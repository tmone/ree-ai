# Crawl4AI Numeric Filtering Guide

## ğŸ¯ Problem Solved

**Before:** Crawled data had inconsistent formats (text prices "5,77 tá»·", text areas "95mÂ²") making numeric filtering impossible.

**After:** All data is normalized and stored as NUMERIC values in OpenSearch, enabling proper filtering:
- âœ… `price > 6500000000` (filter giÃ¡ > 6.5 tá»·)
- âœ… `area < 70` (filter diá»‡n tÃ­ch < 70 mÂ²)
- âœ… `bedrooms >= 3` (filter >= 3 phÃ²ng ngá»§)

---

## ğŸ“Š Data Transformation

### Crawled Data (Raw)
```json
{
  "title": "NhÃ  máº·t tiá»n Quáº­n 7",
  "price": "5,77 tá»·",        // âŒ Text - cannot filter
  "area": "95mÂ²",             // âŒ Text - cannot filter
  "location": "Quáº­n 7, TP. Há»“ ChÃ­ Minh",
  "bedrooms": "3",            // âŒ String
  "bathrooms": 2
}
```

### Normalized Data (Stored in OpenSearch)
```json
{
  "title": "NhÃ  máº·t tiá»n Quáº­n 7",
  "price": 5770000000,        // âœ… Numeric - can filter!
  "price_display": "5.77 tá»·", // For UI display
  "area": 95.0,               // âœ… Numeric - can filter!
  "area_display": "95 mÂ²",    // For UI display
  "district": "Quáº­n 7",       // âœ… Extracted
  "city": "Há»“ ChÃ­ Minh",      // âœ… Extracted
  "bedrooms": 3,              // âœ… Integer
  "bathrooms": 2              // âœ… Integer
}
```

---

## ğŸš€ Setup Instructions

### Step 1: Create OpenSearch Index with Numeric Mapping

**IMPORTANT:** Run this **BEFORE** indexing any properties!

```bash
python scripts/create_opensearch_index_mapping.py
```

This creates the `properties` index with:
- `price`: **double** (numeric filtering enabled)
- `area`: **double** (numeric filtering enabled)
- `bedrooms`: **integer**
- `bathrooms`: **integer**

### Step 2: Crawl and Auto-Index Properties

```bash
# Crawl 100 properties and auto-index to OpenSearch
curl -X POST "http://localhost:8100/crawl/bulk?total=100&auto_index=true"
```

Response:
```json
{
  "success": true,
  "count": 100,
  "indexed_count": 100,
  "total_requested": 100,
  "sites": ["batdongsan", "nhatot"],
  "properties": [...]
}
```

### Step 3: Query with Numeric Filters

```bash
# Search properties with price 5-10 tá»· and area < 100 mÂ²
curl -X POST "http://localhost:8081/search" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "nhÃ  quáº­n 7",
    "filters": {
      "min_price": 5000000000,
      "max_price": 10000000000,
      "max_area": 100,
      "min_bedrooms": 3
    },
    "limit": 20
  }'
```

---

## ğŸ“ API Reference

### 1. Crawl with Auto-Index

**Endpoint:** `POST /crawl/bulk`

**Parameters:**
- `total` (int): Number of properties to crawl (max: 10,000)
- `sites` (string): Comma-separated sites: "batdongsan,nhatot"
- `auto_index` (bool): Auto-index to OpenSearch (default: `true`)

**Example:**
```bash
POST /crawl/bulk?total=500&sites=batdongsan&auto_index=true
```

**Response:**
```json
{
  "success": true,
  "count": 500,
  "indexed_count": 498,  // 498/500 indexed successfully
  "total_requested": 500,
  "sites": ["batdongsan"],
  "properties": [...]
}
```

---

### 2. Search with Filters

**Endpoint:** `POST /search`

**Request Body:**
```json
{
  "query": "nhÃ  quáº­n 7",
  "filters": {
    "property_type": "nhÃ  phá»‘",
    "region": "Quáº­n 7",
    "min_price": 5000000000,    // >= 5 tá»·
    "max_price": 10000000000,   // <= 10 tá»·
    "min_area": 60,             // >= 60 mÂ²
    "max_area": 100,            // <= 100 mÂ²
    "min_bedrooms": 3           // >= 3 phÃ²ng ngá»§
  },
  "limit": 20
}
```

**Response:**
```json
{
  "results": [
    {
      "property_id": "nha-1",
      "title": "NhÃ  máº·t tiá»n Quáº­n 7",
      "price": 5770000000,
      "price_display": "5.77 tá»·",
      "area": 95.0,
      "area_display": "95 mÂ²",
      "district": "Quáº­n 7",
      "city": "Há»“ ChÃ­ Minh",
      "bedrooms": 3,
      "bathrooms": 2,
      "score": 8.5
    }
  ],
  "total": 15,
  "execution_time_ms": 45.2
}
```

---

### 3. Bulk Insert (Manual)

**Endpoint:** `POST /bulk-insert`

Use this if you want to manually index normalized properties:

```bash
curl -X POST "http://localhost:8081/bulk-insert" \
  -H "Content-Type: application/json" \
  -d '[
    {
      "title": "NhÃ  test",
      "price": 5000000000,
      "price_display": "5 tá»·",
      "area": 100.0,
      "area_display": "100 mÂ²",
      "district": "Quáº­n 7",
      "city": "Há»“ ChÃ­ Minh",
      "bedrooms": 3,
      "bathrooms": 2,
      "url": "https://example.com/nha-1",
      "source": "manual"
    }
  ]'
```

**Response:**
```json
{
  "indexed_count": 1,
  "failed_count": 0,
  "errors": null
}
```

---

## ğŸ§ª Testing

### Test Normalized Data

```bash
# Run normalization tests
python shared/utils/data_normalizer.py
```

Expected output:
```
=== PRICE NORMALIZATION ===
5 tá»·                 â†’   5,000,000,000 VNÄ â†’ 5.00 tá»·
5,77 tá»·              â†’   5,770,000,000 VNÄ â†’ 5.77 tá»·
3.2 triá»‡u            â†’       3,200,000 VNÄ â†’ 3.2 triá»‡u

=== AREA NORMALIZATION ===
95mÂ²                 â†’       95.0 mÂ² â†’ 95 mÂ²
120.5m2              â†’      120.5 mÂ² â†’ 120.5 mÂ²

âœ… ALL TESTS PASSED!
```

### Verify OpenSearch Filtering

```bash
# Create sample data and test filtering
# (See CRAWL4AI_NUMERIC_FILTERING.md for details)
```

---

## ğŸ¨ Display in Open WebUI

Properties are displayed with formatted values:

```
ğŸ  NhÃ  máº·t tiá»n Quáº­n 7
ğŸ’° GiÃ¡: 5.77 tá»·                 â† from price_display
ğŸ“ Quáº­n 7, Há»“ ChÃ­ Minh           â† from district + city
ğŸ›ï¸ 3 phÃ²ng ngá»§                  â† from bedrooms
ğŸ“ 95 mÂ²                        â† from area_display
```

Backend filtering uses numeric values:
- `price: 5770000000` (numeric)
- `area: 95.0` (numeric)

---

## âš™ï¸ Configuration

### Environment Variables

```bash
# .env
OPENSEARCH_HOST=localhost
OPENSEARCH_PORT=9200
OPENSEARCH_USER=admin
OPENSEARCH_PASSWORD=admin
OPENSEARCH_PROPERTIES_INDEX=properties
```

### Index Settings

The `properties` index has:
- **Shards:** 1
- **Replicas:** 1
- **Max Results:** 10,000
- **Dynamic Mapping:** Enabled (allows unlimited fields)

---

## ğŸ”§ Troubleshooting

### Issue: Filters not working

**Cause:** Index created without numeric mapping

**Fix:**
```bash
# Delete and recreate index
python scripts/create_opensearch_index_mapping.py
# Re-index properties
curl -X POST "http://localhost:8100/crawl/bulk?total=100&auto_index=true"
```

### Issue: Price/area still text

**Cause:** Normalization not applied

**Fix:** Check crawler logs for normalization errors:
```bash
docker-compose logs crawler | grep "normalize"
```

### Issue: Auto-index failing

**Cause:** DB Gateway not accessible

**Fix:**
```bash
# Check DB Gateway health
curl http://localhost:8081/health

# Check network connectivity
docker-compose logs db-gateway
```

---

## ğŸ“Œ Key Files

- **Normalization:** `shared/utils/data_normalizer.py`
- **Crawler Service:** `services/crawler/main.py`
- **DB Gateway:** `services/db_gateway/main.py`
- **Index Mapping:** `scripts/create_opensearch_index_mapping.py`

---

## ğŸ¯ Example Queries

### Find cheap properties (< 3 tá»·)
```json
{
  "query": "nhÃ ",
  "filters": {
    "max_price": 3000000000
  }
}
```

### Find small apartments (< 60 mÂ²)
```json
{
  "query": "cÄƒn há»™",
  "filters": {
    "max_area": 60
  }
}
```

### Find family homes (3-4 bedrooms, 80-120 mÂ²)
```json
{
  "query": "nhÃ  gia Ä‘Ã¬nh",
  "filters": {
    "min_bedrooms": 3,
    "max_bedrooms": 4,
    "min_area": 80,
    "max_area": 120
  }
}
```

### Find luxury properties (> 15 tá»·, > 150 mÂ²)
```json
{
  "query": "biá»‡t thá»± cao cáº¥p",
  "filters": {
    "min_price": 15000000000,
    "min_area": 150,
    "min_bedrooms": 4
  }
}
```

---

## âœ… Summary

**What Changed:**
1. âœ… Data normalization: text â†’ numeric
2. âœ… Auto-indexing after crawl
3. âœ… Numeric filtering enabled
4. âœ… Display formatting preserved

**What You Can Do Now:**
- âœ… Filter by price range (VND)
- âœ… Filter by area range (mÂ²)
- âœ… Filter by bedrooms/bathrooms (integer)
- âœ… Combine multiple filters
- âœ… Sort by price/area

**What's Maintained:**
- âœ… Flexible schema (unlimited fields)
- âœ… Full-text search (BM25)
- âœ… Nice UI display formatting
- âœ… Backward compatible

---

Need help? Check the logs:
```bash
docker-compose logs -f crawler
docker-compose logs -f db-gateway
docker-compose logs -f rag-service
```
