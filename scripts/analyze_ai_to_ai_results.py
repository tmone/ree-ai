"""
Analyze AI-to-AI Test Results - Find Insights for Prompt Optimization
=====================================================================
Ph√¢n t√≠ch k·∫øt qu·∫£ test ƒë·ªÉ c·∫£i ti·∫øn prompts ·ªü Layer 3 services
"""
import json
import sys
from collections import defaultdict
from typing import Dict, List

def load_results(filename: str) -> Dict:
    """Load JSON results"""
    with open(filename, 'r', encoding='utf-8') as f:
        return json.load(f)

def analyze_conversation(conv: Dict) -> Dict:
    """Analyze single conversation for issues"""
    issues = []
    insights = []

    scenario = conv['scenario']
    turns = conv['total_turns']
    score = conv['final_score']
    history = conv['conversation_history']

    # Issue 1: Too many turns (>8 for complete info)
    if score == 100 and turns > 6:
        issues.append({
            "type": "INEFFICIENT_COMPLETION",
            "severity": "MEDIUM",
            "description": f"ƒê·∫°t 100% nh∆∞ng m·∫•t {turns} turns (n√™n <6)",
            "suggestion": "Orchestrator n√™n k·∫øt th√∫c ngay khi ƒë·∫°t 100%"
        })

    # Issue 2: Incomplete after max turns
    if score < 100:
        issues.append({
            "type": "INCOMPLETE_DATA",
            "severity": "HIGH",
            "description": f"Ch·ªâ ƒë·∫°t {score}% sau {turns} turns",
            "suggestion": "Attribute Extraction ho·∫∑c Completeness Check c√≥ v·∫•n ƒë·ªÅ"
        })

    # Issue 3: Repetitive system responses
    system_msgs = [msg['content'] for msg in history if msg['role'] == 'assistant']
    if len(system_msgs) > 2:
        repeated_count = sum(1 for i in range(len(system_msgs)-1)
                            if system_msgs[i] == system_msgs[i+1])
        if repeated_count > 2:
            issues.append({
                "type": "REPETITIVE_RESPONSE",
                "severity": "HIGH",
                "description": f"H·ªá th·ªëng l·∫∑p l·∫°i response {repeated_count} l·∫ßn",
                "suggestion": "Orchestrator kh√¥ng nh·∫≠n ƒë∆∞·ª£c update t·ª´ Attribute Extraction"
            })

    # Issue 4: User frustration signals
    user_msgs = [msg['content'].lower() for msg in history if msg['role'] == 'user']
    frustration_keywords = ['l·ªói', 'sai', 'nh·∫ßm', '·ªßa', 'h·∫£', 'm√†', 'r·ªìi m√†', 'ƒë√£ g·ª≠i']
    frustrated_turns = sum(1 for msg in user_msgs if any(kw in msg for kw in frustration_keywords))

    if frustrated_turns >= 2:
        issues.append({
            "type": "USER_FRUSTRATION",
            "severity": "CRITICAL",
            "description": f"User th·∫•t v·ªçng/ph√†n n√†n {frustrated_turns} l·∫ßn",
            "suggestion": "H·ªá th·ªëng kh√¥ng hi·ªÉu ho·∫∑c kh√¥ng x·ª≠ l√Ω ƒë√∫ng input"
        })

    # Issue 5: AI quality - format copying
    for i, msg in enumerate(history):
        if msg['role'] == 'user' and '(Ho√†n thi·ªán:' in msg['content']:
            issues.append({
                "type": "AI_FORMAT_COPYING",
                "severity": "HIGH",
                "description": f"Ollama AI sao ch√©p format h·ªá th·ªëng (turn {i+1})",
                "suggestion": "C·∫ßn c·∫£i thi·ªán prompt Ollama v·ªõi stop tokens"
            })
            break

    # Insight 1: Optimal completion
    if score == 100 and turns <= 4 and len(issues) == 0:
        insights.append({
            "type": "OPTIMAL_FLOW",
            "description": f"Ho√†n h·∫£o! {turns} turns, kh√¥ng l·ªói",
            "scenario": scenario
        })

    # Insight 2: Multi-language support needed
    if 'english' in scenario.lower() or 'ti·∫øng anh' in scenario.lower():
        insights.append({
            "type": "MULTILINGUAL_CAPABILITY",
            "description": "Test ƒëa ng√¥n ng·ªØ",
            "scenario": scenario
        })

    return {
        "scenario": scenario,
        "turns": turns,
        "score": score,
        "issues": issues,
        "insights": insights
    }

def generate_summary(analyses: List[Dict]) -> Dict:
    """Generate comprehensive summary"""

    # Categorize by outcome
    perfect = [a for a in analyses if a['score'] == 100 and a['turns'] <= 5 and not a['issues']]
    good = [a for a in analyses if a['score'] == 100 and (a['turns'] > 5 or a['issues'])]
    incomplete = [a for a in analyses if a['score'] < 100]

    # Group issues by type
    issue_types = defaultdict(list)
    for analysis in analyses:
        for issue in analysis['issues']:
            issue_types[issue['type']].append({
                'scenario': analysis['scenario'],
                'severity': issue['severity'],
                'description': issue['description'],
                'suggestion': issue['suggestion']
            })

    # Calculate metrics
    total = len(analyses)
    avg_turns = sum(a['turns'] for a in analyses) / total
    avg_score = sum(a['score'] for a in analyses) / total

    return {
        "metrics": {
            "total_scenarios": total,
            "perfect_count": len(perfect),
            "good_count": len(good),
            "incomplete_count": len(incomplete),
            "avg_turns": round(avg_turns, 1),
            "avg_score": round(avg_score, 1),
            "success_rate": round((len(perfect) + len(good)) / total * 100, 1)
        },
        "issue_summary": {
            issue_type: {
                "count": len(issues),
                "severity": issues[0]['severity'],
                "examples": issues[:3]  # Top 3 examples
            }
            for issue_type, issues in issue_types.items()
        },
        "perfect_scenarios": [a['scenario'] for a in perfect],
        "problematic_scenarios": [
            {"scenario": a['scenario'], "issues": len(a['issues'])}
            for a in sorted(analyses, key=lambda x: len(x['issues']), reverse=True)[:5]
        ]
    }

def generate_prompt_recommendations(summary: Dict, analyses: List[Dict]) -> List[Dict]:
    """Generate specific prompt improvement recommendations"""
    recommendations = []

    # Rec 1: Handle special property types (land, etc.)
    land_issues = [a for a in analyses if 'ƒë·∫•t' in a['scenario'].lower() and a['score'] < 100]
    if land_issues:
        recommendations.append({
            "priority": "HIGH",
            "service": "Attribute Extraction Service",
            "file": "services/attribute_extraction/prompts.py",
            "issue": "Kh√¥ng x·ª≠ l√Ω ƒë∆∞·ª£c property types kh√¥ng c√≥ ph√≤ng ng·ªß (ƒë·∫•t, parking, commercial)",
            "current_prompt": "bedrooms: Optional[int] - Required field",
            "improved_prompt": """bedrooms: Optional[int] = Field(None, description="S·ªë ph√≤ng ng·ªß. CH√ö √ù: V·ªõi ƒë·∫•t/parking/commercial, gi√° tr·ªã n√†y c√≥ th·ªÉ = 0 ho·∫∑c null")

EDGE CASES:
- ƒê·∫•t n√¥ng nghi·ªáp, ƒë·∫•t th·ªï c∆∞ ‚Üí bedrooms = null ho·∫∑c 0
- Parking lot, nh√† kho ‚Üí bedrooms = null ho·∫∑c 0
- Commercial property ‚Üí bedrooms = null (tr·ª´ khi c√≥ cƒÉn h·ªô d·ªãch v·ª•)""",
            "affected_scenarios": [a['scenario'] for a in land_issues]
        })

    # Rec 2: Better price parsing (decimal support)
    price_issues = [a for a in analyses
                   if any(i['type'] == 'USER_FRUSTRATION' and 'gi√°' in i['description'].lower()
                         for i in a['issues'])]
    if price_issues:
        recommendations.append({
            "priority": "HIGH",
            "service": "Attribute Extraction Service",
            "file": "services/attribute_extraction/prompts.py",
            "issue": "Kh√¥ng parse ƒë√∫ng gi√° c√≥ d·∫•u ph·∫©y (5,5 t·ª∑ ‚Üí 5.0 t·ª∑)",
            "current_prompt": '"2.5 t·ª∑" ‚Üí 2500000000',
            "improved_prompt": '''PRICE EXTRACTION RULES:
- "2.5 t·ª∑" ‚Üí 2500000000
- "2,5 t·ª∑" ‚Üí 2500000000  # SUPPORT COMMA
- "20.5 t·ª∑" ‚Üí 20500000000
- "5 t·ª∑ 500 tri·ªáu" ‚Üí 5500000000
- "3 tri·ªáu/th√°ng" ‚Üí 3000000 (rental)
- "500k/ng√†y" ‚Üí 500000 (daily rental)

CRITICAL: Vietnamese users often use COMMA (,) instead of DOT (.) for decimals!''',
            "affected_scenarios": [a['scenario'] for a in price_issues]
        })

    # Rec 3: Rental price detection
    rent_issues = [a for a in analyses
                  if 'thu√™' in a['scenario'].lower() and a['score'] < 100]
    if rent_issues:
        recommendations.append({
            "priority": "MEDIUM",
            "service": "Attribute Extraction Service",
            "file": "services/attribute_extraction/prompts.py",
            "issue": "Kh√¥ng nh·∫≠n d·∫°ng gi√° thu√™ v·ªõi format 'X tri·ªáu m·ªôt th√°ng'",
            "current_prompt": 'r"(\\d+)\\s*(?:tri·ªáu|million)/(?:th√°ng|month)"',
            "improved_prompt": '''RENTAL PRICE PATTERNS:
- "15 tri·ªáu/th√°ng" ‚Üí price_rent = 15000000
- "15 tri·ªáu m·ªôt th√°ng" ‚Üí price_rent = 15000000  # NEW
- "15 tri·ªáu m·ªói th√°ng" ‚Üí price_rent = 15000000  # NEW
- "15 tri·ªáu 1 th√°ng" ‚Üí price_rent = 15000000    # NEW
- "500k/ng√†y" ‚Üí daily_rate = 500000, price_rent = 15000000 (estimate)''',
            "affected_scenarios": [a['scenario'] for a in rent_issues]
        })

    # Rec 4: Conversation ending logic
    if summary['metrics']['avg_turns'] > 6:
        recommendations.append({
            "priority": "HIGH",
            "service": "Orchestrator Service",
            "file": "services/orchestrator/prompts.py",
            "issue": "Orchestrator kh√¥ng k·∫øt th√∫c h·ªôi tho·∫°i khi ƒë√£ ƒë·ªß th√¥ng tin",
            "current_prompt": "N/A - Business logic issue",
            "improved_prompt": '''ADD TO ORCHESTRATOR FLOW:

if completeness_score >= 100:
    return {
        "response": "‚úÖ Ho√†n t·∫•t! Tin ƒëƒÉng ƒë√£ ƒë∆∞·ª£c l∆∞u. C·∫£m ∆°n b·∫°n!",
        "end_conversation": True,  # NEW FIELD
        "metadata": {"completeness_score": 100, "ready_to_publish": True}
    }

KH√îNG l·∫∑p l·∫°i "Tin ƒëƒÉng s·∫µn s√†ng" nhi·ªÅu l·∫ßn!''',
            "affected_scenarios": ["ALL"]
        })

    # Rec 5: User frustration detection
    frustration_count = sum(1 for a in analyses
                           if any(i['type'] == 'USER_FRUSTRATION' for i in a['issues']))
    if frustration_count >= 3:
        recommendations.append({
            "priority": "CRITICAL",
            "service": "Orchestrator Service",
            "file": "services/orchestrator/prompts.py",
            "issue": "H·ªá th·ªëng kh√¥ng ph√°t hi·ªán user frustration ƒë·ªÉ ƒëi·ªÅu ch·ªânh",
            "current_prompt": "N/A",
            "improved_prompt": '''ADD USER FRUSTRATION DETECTION:

FRUSTRATION_SIGNALS = [
    "l·ªói", "sai", "nh·∫ßm", "·ªßa", "h·∫£",
    "r·ªìi m√†", "ƒë√£ g·ª≠i", "ƒë√£ nh·∫≠p", "kh√¥ng hi·ªÉu sao"
]

if detect_frustration(user_message):
    # Option 1: Apologize and confirm
    return "Xin l·ªói b·∫°n! ƒê·ªÉ em ki·ªÉm tra l·∫°i th√¥ng tin b·∫°n ƒë√£ cung c·∫•p..."

    # Option 2: Reset extraction
    return "Em xin l·ªói, c√≥ v·∫ª c√≥ s·ª± nh·∫ßm l·∫´n. B·∫°n c√≥ th·ªÉ nh·∫≠p l·∫°i to√†n b·ªô th√¥ng tin kh√¥ng?"

    # Option 3: Escalate to human
    return "Em xin l·ªói v√¨ s·ª± b·∫•t ti·ªán. Em s·∫Ω chuy·ªÉn b·∫°n sang b·ªô ph·∫≠n h·ªó tr·ª£..."''',
            "affected_scenarios": [a['scenario'] for a in analyses
                                  if any(i['type'] == 'USER_FRUSTRATION' for i in a['issues'])]
        })

    # Rec 6: Multi-language support
    recommendations.append({
        "priority": "MEDIUM",
        "service": "Attribute Extraction Service + Classification Service",
        "file": "services/attribute_extraction/prompts.py, services/classification/prompts.py",
        "issue": "C·∫ßn h·ªó tr·ª£ r√µ r√†ng c√°c ng√¥n ng·ªØ: VI, EN, TH, JA",
        "current_prompt": "Prompts ch·ªâ c√≥ ti·∫øng Vi·ªát",
        "improved_prompt": '''ADD MULTILINGUAL SUPPORT:

LANGUAGE_DETECTION:
- Vietnamese: Contains "ƒÉ", "∆°", "∆∞", "ƒë", "qu·∫≠n", "ph√≤ng ng·ªß"
- English: Contains "bedroom", "district", "property"
- Thai: Contains "‡∏´‡πâ‡∏≠‡∏á‡∏ô‡∏≠‡∏ô", "‡πÄ‡∏Ç‡∏ï", "‡∏ö‡∏≤‡∏ó"
- Japanese: Contains "„Éô„ÉÉ„Éâ„É´„Éº„É†", "Âå∫", "ÂÜÜ"

NORMALIZED FIELD MAPPING:
{
    "bedrooms": {
        "vi": ["ph√≤ng ng·ªß", "pn", "ph√≤ng"],
        "en": ["bedroom", "bed", "br"],
        "th": ["‡∏´‡πâ‡∏≠‡∏á‡∏ô‡∏≠‡∏ô"],
        "ja": ["„Éô„ÉÉ„Éâ„É´„Éº„É†", "ÂØùÂÆ§"]
    },
    "district": {
        "vi": ["qu·∫≠n", "huy·ªán", "q.", "q"],
        "en": ["district", "area", "zone"],
        "th": ["‡πÄ‡∏Ç‡∏ï", "‡∏≠‡∏≥‡πÄ‡∏†‡∏≠"],
        "ja": ["Âå∫", "Âú∞Âå∫"]
    }
}

Extract entities language-agnostically, then normalize to English fields.''',
        "affected_scenarios": ["ALL - Future internationalization"]
    })

    return recommendations

def print_analysis_report(results: Dict, analyses: List[Dict], summary: Dict, recommendations: List[Dict]):
    """Print comprehensive analysis report"""

    print("=" * 120)
    print("üìä AI-TO-AI TEST ANALYSIS REPORT")
    print("=" * 120)
    print(f"\nTest file: {results['metadata']['timestamp']}")
    print(f"Total scenarios tested: {results['metadata']['total_scenarios']}")

    print("\n" + "=" * 120)
    print("üìà OVERALL METRICS")
    print("=" * 120)
    metrics = summary['metrics']
    print(f"  ‚úÖ Perfect (‚â§5 turns, 100%, no issues): {metrics['perfect_count']}/{metrics['total_scenarios']}")
    print(f"  ‚ö†Ô∏è  Good (100% but issues):              {metrics['good_count']}/{metrics['total_scenarios']}")
    print(f"  ‚ùå Incomplete (<100%):                   {metrics['incomplete_count']}/{metrics['total_scenarios']}")
    print(f"  üìä Average turns:                        {metrics['avg_turns']}")
    print(f"  üìä Average score:                        {metrics['avg_score']}%")
    print(f"  üìä Success rate:                         {metrics['success_rate']}%")

    print("\n" + "=" * 120)
    print("üéØ PERFECT SCENARIOS (Best practices)")
    print("=" * 120)
    for scenario in summary['perfect_scenarios']:
        print(f"  ‚úÖ {scenario}")

    print("\n" + "=" * 120)
    print("‚ö†Ô∏è  PROBLEMATIC SCENARIOS (Need attention)")
    print("=" * 120)
    for item in summary['problematic_scenarios']:
        print(f"  ‚ùå {item['scenario']} ({item['issues']} issues)")

    print("\n" + "=" * 120)
    print("üêõ ISSUE BREAKDOWN")
    print("=" * 120)
    for issue_type, data in summary['issue_summary'].items():
        print(f"\n  {issue_type} [{data['severity']}] - {data['count']} occurrences:")
        for ex in data['examples']:
            print(f"    - {ex['scenario']}")
            print(f"      {ex['description']}")
            print(f"      üí° {ex['suggestion']}")

    print("\n" + "=" * 120)
    print("üöÄ PROMPT OPTIMIZATION RECOMMENDATIONS")
    print("=" * 120)
    for i, rec in enumerate(recommendations, 1):
        print(f"\n[{i}] {rec['service']} - Priority: {rec['priority']}")
        print(f"    üìÅ File: {rec['file']}")
        print(f"    üêõ Issue: {rec['issue']}")
        print(f"\n    ‚ùå Current:")
        for line in rec['current_prompt'].split('\n'):
            print(f"       {line}")
        print(f"\n    ‚úÖ Improved:")
        for line in rec['improved_prompt'].split('\n'):
            print(f"       {line}")
        print(f"\n    üìã Affected: {len(rec['affected_scenarios'])} scenarios")
        if len(rec['affected_scenarios']) <= 3:
            for scenario in rec['affected_scenarios']:
                print(f"       - {scenario}")

    print("\n" + "=" * 120)
    print("üí° NEXT STEPS")
    print("=" * 120)
    print("  1. Review recommendations above")
    print("  2. Update prompts in respective service files")
    print("  3. Re-run AI-to-AI tests to validate improvements")
    print("  4. Monitor production metrics for real user impact")
    print("  5. Continue iterative testing with more edge cases")
    print("=" * 120)

def main():
    """Main analysis"""
    if len(sys.argv) < 2:
        print("Usage: python analyze_ai_to_ai_results.py <json_file>")
        sys.exit(1)

    filename = sys.argv[1]

    # Load and analyze
    results = load_results(filename)
    analyses = [analyze_conversation(conv) for conv in results['results']]
    summary = generate_summary(analyses)
    recommendations = generate_prompt_recommendations(summary, analyses)

    # Print report
    print_analysis_report(results, analyses, summary, recommendations)

    # Save analysis to file
    output_file = filename.replace('.json', '_analysis.json')
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            "analyses": analyses,
            "summary": summary,
            "recommendations": recommendations
        }, f, ensure_ascii=False, indent=2)

    print(f"\nüìÑ Detailed analysis saved to: {output_file}")

if __name__ == "__main__":
    main()
