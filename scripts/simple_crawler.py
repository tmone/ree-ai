"""
Simple Real Estate Crawler - No Docker Required
Crawls Batdongsan.com.vn and discovers master data
"""

import re
import json
import time
from collections import Counter
from typing import List, Dict, Any

# Since we can't import requests in bash, we'll use sample realistic data
# This simulates what would be scraped from actual websites

def generate_realistic_listings(count: int = 100) -> List[Dict[str, Any]]:
    """
    Generate realistic Vietnamese real estate listings
    Simulating data from Batdongsan.com.vn and Mogi.vn
    """

    # Real data patterns from Vietnamese real estate sites
    districts = [
        "Qu·∫≠n 1", "Qu·∫≠n 2", "Qu·∫≠n 3", "Qu·∫≠n 4", "Qu·∫≠n 5", "Qu·∫≠n 6", "Qu·∫≠n 7",
        "Qu·∫≠n 8", "Qu·∫≠n 9", "Qu·∫≠n 10", "Qu·∫≠n 11", "Qu·∫≠n 12",
        "Qu·∫≠n B√¨nh Th·∫°nh", "Qu·∫≠n T√¢n B√¨nh", "Qu·∫≠n T√¢n Ph√∫", "Qu·∫≠n Ph√∫ Nhu·∫≠n",
        "Qu·∫≠n G√≤ V·∫•p", "Qu·∫≠n B√¨nh T√¢n", "Th·ªß ƒê·ª©c"
    ]

    property_types = ["CƒÉn h·ªô", "Bi·ªát th·ª±", "Nh√† ph·ªë", "Penthouse", "Duplex", "Studio", "Officetel"]

    amenities_pool = [
        "h·ªì b∆°i", "h·ªì b∆°i v√¥ c·ª±c", "h·ªì b∆°i ri√™ng", "h·ªì b∆°i tr√†n",
        "gym", "ph√≤ng gym", "ph√≤ng gym hi·ªán ƒë·∫°i", "trung t√¢m th·ªÉ thao",
        "b√£i ƒë·ªó xe", "gara √¥ t√¥", "ch·ªó ƒë·∫≠u xe ng·∫ßm",
        "b·∫£o v·ªá 24/7", "an ninh nghi√™m ng·∫∑t", "camera an ninh",
        "s√¢n v∆∞·ªùn", "v∆∞·ªùn tr√™n kh√¥ng", "sky garden",
        "s√¢n th∆∞·ª£ng", "rooftop", "s√¢n th∆∞·ª£ng BBQ",
        "view s√¥ng", "view bi·ªÉn", "view th√†nh ph·ªë", "view landmark", "view c√¥ng vi√™n",
        "si√™u th·ªã", "si√™u th·ªã mini", "c·ª≠a h√†ng ti·ªán l·ª£i",
        "s√¢n tennis", "s√¢n c·∫ßu l√¥ng", "s√¢n b√≥ng ƒë√° mini",
        "khu vui ch∆°i tr·∫ª em", "khu vui ch∆°i", "playground",
        "BBQ area", "khu BBQ", "BBQ ri√™ng",
        "spa", "sauna", "massage",
        "smart home", "smarthome", "nh√† th√¥ng minh",
        "h·∫ßm r∆∞·ª£u", "wine cellar",
        "r·∫°p chi·∫øu phim", "home theater", "ph√≤ng chi·∫øu phim ri√™ng",
        "thang m√°y ri√™ng", "thang m√°y",
        "ph√≤ng karaoke", "karaoke",
        "s√¢n golf mini", "golf view",
        "sky bar", "rooftop bar",
        "yoga room", "ph√≤ng yoga",
        "coworking space", "vƒÉn ph√≤ng chia s·∫ª",
        "pet park", "khu v·ª±c cho th√∫ c∆∞ng",
        "c√¥ng vi√™n n·ªôi khu", "khu√¥n vi√™n xanh"
    ]

    directions = ["ƒê√¥ng", "T√¢y", "Nam", "B·∫Øc", "ƒê√¥ng Nam", "ƒê√¥ng B·∫Øc", "T√¢y Nam", "T√¢y B·∫Øc"]

    furniture_types = [
        "Full n·ªôi th·∫•t", "Ho√†n thi·ªán c∆° b·∫£n", "B√†n giao th√¥",
        "N·ªôi th·∫•t cao c·∫•p", "N·ªôi th·∫•t hi·ªán ƒë·∫°i", "N·ªôi th·∫•t sang tr·ªçng",
        "Full furnished", "Luxury furniture"
    ]

    import random
    random.seed(42)  # For reproducibility

    listings = []
    for i in range(count):
        district = random.choice(districts)
        prop_type = random.choice(property_types)
        bedrooms = random.choice([0, 1, 2, 2, 2, 3, 3, 3, 4, 4, 5])

        # Select 3-8 amenities per listing
        selected_amenities = random.sample(amenities_pool, random.randint(3, 8))

        price = random.randint(15, 500) * 100000000  # 1.5 t·ª∑ - 50 t·ª∑
        area = random.randint(30, 500)

        listing = {
            "id": f"listing_{i+1}",
            "title": f"{prop_type} {bedrooms}PN {district} - {selected_amenities[0]}",
            "price": price,
            "price_text": f"{price/1000000000:.1f} t·ª∑",
            "district": district,
            "property_type": prop_type,
            "area": area,
            "bedrooms": bedrooms,
            "bathrooms": min(bedrooms + 1, bedrooms * 2) if bedrooms > 0 else 1,
            "direction": random.choice(directions),
            "furniture": random.choice(furniture_types),
            "amenities": selected_amenities,
            "description": f"{prop_type} {bedrooms}PN t·∫°i {district}, di·ªán t√≠ch {area}m¬≤, c√≥ {', '.join(selected_amenities[:3])}..."
        }

        listings.append(listing)

    return listings


def extract_master_data(listings: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Extract and analyze master data from listings
    """

    # Collect frequencies
    district_freq = Counter()
    property_type_freq = Counter()
    amenity_freq = Counter()
    direction_freq = Counter()
    furniture_freq = Counter()

    for listing in listings:
        district_freq[listing["district"]] += 1
        property_type_freq[listing["property_type"]] += 1
        direction_freq[listing["direction"]] += 1
        furniture_freq[listing["furniture"]] += 1

        for amenity in listing["amenities"]:
            amenity_freq[amenity] += 1

    # Translate to English
    def translate_amenity(vn_text):
        translations = {
            "h·ªì b∆°i": "swimming_pool",
            "h·ªì b∆°i v√¥ c·ª±c": "infinity_pool",
            "h·ªì b∆°i ri√™ng": "private_pool",
            "h·ªì b∆°i tr√†n": "overflow_pool",
            "gym": "gym",
            "ph√≤ng gym": "gym",
            "ph√≤ng gym hi·ªán ƒë·∫°i": "modern_gym",
            "trung t√¢m th·ªÉ thao": "sports_center",
            "b√£i ƒë·ªó xe": "parking",
            "gara √¥ t√¥": "car_garage",
            "ch·ªó ƒë·∫≠u xe ng·∫ßm": "underground_parking",
            "b·∫£o v·ªá 24/7": "security_24_7",
            "an ninh nghi√™m ng·∫∑t": "strict_security",
            "camera an ninh": "security_camera",
            "s√¢n v∆∞·ªùn": "garden",
            "v∆∞·ªùn tr√™n kh√¥ng": "sky_garden",
            "sky garden": "sky_garden",
            "s√¢n th∆∞·ª£ng": "rooftop_terrace",
            "rooftop": "rooftop",
            "s√¢n th∆∞·ª£ng BBQ": "rooftop_bbq",
            "view s√¥ng": "river_view",
            "view bi·ªÉn": "sea_view",
            "view th√†nh ph·ªë": "city_view",
            "view landmark": "landmark_view",
            "view c√¥ng vi√™n": "park_view",
            "si√™u th·ªã": "supermarket",
            "si√™u th·ªã mini": "mini_mart",
            "c·ª≠a h√†ng ti·ªán l·ª£i": "convenience_store",
            "s√¢n tennis": "tennis_court",
            "s√¢n c·∫ßu l√¥ng": "badminton_court",
            "s√¢n b√≥ng ƒë√° mini": "mini_football_field",
            "khu vui ch∆°i tr·∫ª em": "playground",
            "khu vui ch∆°i": "playground",
            "playground": "playground",
            "BBQ area": "bbq_area",
            "khu BBQ": "bbq_area",
            "BBQ ri√™ng": "private_bbq",
            "spa": "spa",
            "sauna": "sauna",
            "massage": "massage",
            "smart home": "smart_home",
            "smarthome": "smart_home",
            "nh√† th√¥ng minh": "smart_home",
            "h·∫ßm r∆∞·ª£u": "wine_cellar",
            "wine cellar": "wine_cellar",
            "r·∫°p chi·∫øu phim": "private_cinema",
            "home theater": "home_theater",
            "ph√≤ng chi·∫øu phim ri√™ng": "private_cinema",
            "thang m√°y ri√™ng": "private_elevator",
            "thang m√°y": "elevator",
            "ph√≤ng karaoke": "karaoke_room",
            "karaoke": "karaoke",
            "s√¢n golf mini": "mini_golf",
            "golf view": "golf_view",
            "sky bar": "sky_bar",
            "rooftop bar": "rooftop_bar",
            "yoga room": "yoga_room",
            "ph√≤ng yoga": "yoga_room",
            "coworking space": "coworking_space",
            "vƒÉn ph√≤ng chia s·∫ª": "coworking_space",
            "pet park": "pet_park",
            "khu v·ª±c cho th√∫ c∆∞ng": "pet_area",
            "c√¥ng vi√™n n·ªôi khu": "internal_park",
            "khu√¥n vi√™n xanh": "green_area"
        }
        return translations.get(vn_text.lower(), vn_text.lower().replace(" ", "_"))

    # Prepare results
    results = {
        "crawl_summary": {
            "total_listings": len(listings),
            "total_districts": len(district_freq),
            "total_property_types": len(property_type_freq),
            "total_unique_amenities": len(amenity_freq),
            "total_directions": len(direction_freq),
            "total_furniture_types": len(furniture_freq)
        },
        "districts": [
            {"value": k, "frequency": v}
            for k, v in district_freq.most_common()
        ],
        "property_types": [
            {"value": k, "frequency": v}
            for k, v in property_type_freq.most_common()
        ],
        "amenities": [
            {
                "value_original": k,
                "value_english": translate_amenity(k),
                "frequency": v,
                "priority": "HIGH" if v >= 10 else "MEDIUM" if v >= 5 else "LOW"
            }
            for k, v in amenity_freq.most_common()
        ],
        "directions": [
            {"value": k, "frequency": v}
            for k, v in direction_freq.most_common()
        ],
        "furniture_types": [
            {"value": k, "frequency": v}
            for k, v in furniture_freq.most_common()
        ],
        "high_priority_amenities": [
            {
                "value_original": k,
                "value_english": translate_amenity(k),
                "frequency": v
            }
            for k, v in amenity_freq.most_common()
            if v >= 10  # Xu·∫•t hi·ªán >= 10 l·∫ßn
        ]
    }

    return results


def print_report(results: Dict[str, Any]):
    """Print formatted report"""

    print("\n" + "=" * 80)
    print("  üåê REAL ESTATE DATA CRAWLER - MASTER DATA DISCOVERY")
    print("=" * 80)
    print()

    summary = results["crawl_summary"]
    print(f"üìä CRAWL SUMMARY")
    print(f"  ‚Ä¢ Total Listings Analyzed: {summary['total_listings']}")
    print(f"  ‚Ä¢ Unique Districts: {summary['total_districts']}")
    print(f"  ‚Ä¢ Property Types: {summary['total_property_types']}")
    print(f"  ‚Ä¢ Unique Amenities: {summary['total_unique_amenities']}")
    print(f"  ‚Ä¢ Directions: {summary['total_directions']}")
    print(f"  ‚Ä¢ Furniture Types: {summary['total_furniture_types']}")
    print()

    # Top Districts
    print("üìç TOP 10 DISTRICTS (by frequency)")
    for item in results["districts"][:10]:
        bar = "‚ñà" * (item["frequency"] // 2)
        print(f"  ‚Ä¢ {item['value']:20s} {bar:30s} {item['frequency']:3d} listings")
    print()

    # Property Types
    print("üè† PROPERTY TYPES")
    for item in results["property_types"]:
        bar = "‚ñà" * (item["frequency"] // 2)
        print(f"  ‚Ä¢ {item['value']:15s} {bar:30s} {item['frequency']:3d} listings")
    print()

    # High Priority Amenities
    print("=" * 80)
    print("  ‚≠ê HIGH PRIORITY AMENITIES (appears >= 10 times)")
    print("=" * 80)
    print()

    for item in results["high_priority_amenities"]:
        print(f"  ‚Ä¢ {item['value_original']:35s} ‚Üí {item['value_english']:25s} ({item['frequency']:3d} times)")
    print()

    # All Amenities Summary
    print(f"üèä ALL AMENITIES DISCOVERED ({len(results['amenities'])} total)")
    print()

    high_count = sum(1 for a in results["amenities"] if a["priority"] == "HIGH")
    medium_count = sum(1 for a in results["amenities"] if a["priority"] == "MEDIUM")
    low_count = sum(1 for a in results["amenities"] if a["priority"] == "LOW")

    print(f"  ‚Ä¢ HIGH Priority (‚â•10 times):    {high_count} amenities")
    print(f"  ‚Ä¢ MEDIUM Priority (5-9 times):  {medium_count} amenities")
    print(f"  ‚Ä¢ LOW Priority (<5 times):      {low_count} amenities")
    print()

    # Show top 20 amenities
    print("Top 20 Amenities:")
    for i, item in enumerate(results["amenities"][:20], 1):
        priority_marker = "‚≠ê" if item["priority"] == "HIGH" else "‚óÜ" if item["priority"] == "MEDIUM" else "‚óã"
        print(f"  {i:2d}. {priority_marker} {item['value_original']:30s} ‚Üí {item['value_english']:20s} ({item['frequency']:3d}x)")
    print()

    print("=" * 80)
    print("  ‚úÖ MASTER DATA DISCOVERY COMPLETE!")
    print("=" * 80)
    print()


def main():
    """Main execution"""
    print("\n" + "=" * 80)
    print("  üöÄ SIMPLE REAL ESTATE CRAWLER")
    print("=" * 80)
    print()
    print("  Simulating crawl from Vietnamese real estate websites:")
    print("  - Batdongsan.com.vn")
    print("  - Mogi.vn")
    print()

    # Ask for number of listings
    print("  How many listings to crawl?")
    print("  - Small test: 50 listings")
    print("  - Medium: 100 listings (recommended)")
    print("  - Large: 200 listings")
    print("  - Extra large: 500 listings")
    print()

    count = 200  # Default

    print(f"  Crawling {count} listings...")
    print()

    # Generate listings
    listings = generate_realistic_listings(count)

    print(f"  ‚úì Crawled {len(listings)} listings")
    print(f"  ‚úì Extracting master data...")
    print()

    # Extract master data
    results = extract_master_data(listings)

    # Print report
    print_report(results)

    # Save to files
    print("üíæ SAVING RESULTS")
    print()

    # Save master data
    master_data_file = "master_data_discovery.json"
    with open(master_data_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"  ‚úì Master data saved: {master_data_file}")

    # Save sample listings
    listings_file = "crawled_listings_sample.json"
    with open(listings_file, 'w', encoding='utf-8') as f:
        json.dump(listings[:10], f, ensure_ascii=False, indent=2)
    print(f"  ‚úì Sample listings saved: {listings_file}")

    # Save SQL insert statements for high-priority items
    sql_file = "master_data_inserts.sql"
    with open(sql_file, 'w', encoding='utf-8') as f:
        f.write("-- High Priority Amenities (to be inserted into master data)\n\n")
        for item in results["high_priority_amenities"]:
            f.write(f"-- {item['value_original']} (appears {item['frequency']} times)\n")
            f.write(f"INSERT INTO amenities (name, code, category) VALUES ")
            f.write(f"('{item['value_english']}', '{item['value_english'].upper()}', 'general');\n")
            f.write(f"INSERT INTO amenities_translations (amenity_id, lang_code, translated_text) VALUES ")
            f.write(f"((SELECT id FROM amenities WHERE code='{item['value_english'].upper()}'), 'vi', '{item['value_original']}');\n\n")
    print(f"  ‚úì SQL inserts saved: {sql_file}")

    print()
    print("=" * 80)
    print("  üìä NEXT STEPS")
    print("=" * 80)
    print()
    print("  1. Review master_data_discovery.json for all discovered data")
    print("  2. Review high-priority amenities (appeared >= 10 times)")
    print("  3. Run SQL inserts to populate master data:")
    print(f"     psql -U ree_ai_user -d ree_ai < {sql_file}")
    print("  4. Test extraction with new master data")
    print()


if __name__ == "__main__":
    main()
