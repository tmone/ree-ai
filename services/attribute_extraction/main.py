"""
Attribute Extraction Service - CTO Service #4 (Layer 3)
Extracts structured entities from raw user queries using enhanced 3-layer pipeline:
1. NLP Pre-processing - Rule-based entity extraction
2. RAG Context Retrieval - Get similar properties for context
3. Enhanced LLM Extraction - LLM with NLP + RAG hints
4. Post-Validation - Validate against DB distribution
"""
import httpx
import json
import re
from typing import Dict, Any, Optional
from fastapi import HTTPException
from pydantic import BaseModel

from core.base_service import BaseService
from services.attribute_extraction.prompts import AttributeExtractionPrompts, PropertyAttributes
from services.attribute_extraction.nlp_processor import VietnameseNLPProcessor
from services.attribute_extraction.rag_enhancer import RAGContextEnhancer
from services.attribute_extraction.validator import AttributeValidator
from services.attribute_extraction.master_data_validator import MasterDataValidator
from shared.config import settings
from shared.utils.logger import LogEmoji
from shared.i18n import get_multilingual_mapper


class QueryExtractionRequest(BaseModel):
    """Request to extract entities from user query"""
    query: str
    intent: Optional[str] = None  # SEARCH, COMPARE, etc.


class ImageExtractionRequest(BaseModel):
    """Request to extract entities from property images"""
    images: List[str]  # Base64 encoded images
    text_context: Optional[str] = None  # Optional text context to enhance extraction


class QueryExtractionResponse(BaseModel):
    """Response with extracted entities"""
    entities: Dict[str, Any]
    confidence: float
    extracted_from: str  # "query"


class EnhancedExtractionResponse(BaseModel):
    """Response with enhanced extraction using NLP + RAG + LLM pipeline"""
    entities: Dict[str, Any]
    confidence: float
    extracted_from: str
    nlp_entities: Dict[str, Any]  # Entities from NLP layer
    rag_retrieved_count: int  # Number of similar properties used for context
    warnings: list[str]  # Validation warnings
    validation_details: Dict[str, Any]  # Detailed validation info
    # NEW: Confidence-based clarification
    needs_clarification: bool = False  # True if confidence too low
    clarification_questions: Optional[List[str]] = None  # Questions to ask user
    suggestions: Optional[List[Dict[str, Any]]] = None  # Suggested values


class AttributeExtractionService(BaseService):
    """
    Attribute Extraction Service - Layer 3
    Extracts structured entities from raw queries and property descriptions
    """

    def __init__(self):
        super().__init__(
            name="attribute_extraction",
            version="2.0.0",  # Enhanced with NLP + RAG
            capabilities=["entity_extraction", "attribute_extraction", "query_parsing", "nlp_preprocessing", "rag_enhanced"],
            port=8080
        )

        self.http_client = httpx.AsyncClient(timeout=60.0)
        self.core_gateway_url = settings.get_core_gateway_url()
        self.db_gateway_url = settings.get_db_gateway_url()

        # Initialize enhanced components
        self.nlp_processor = VietnameseNLPProcessor()
        self.rag_enhancer = RAGContextEnhancer(self.db_gateway_url)
        self.validator = AttributeValidator()
        self.multilingual_mapper = get_multilingual_mapper()
        self.master_data_validator = MasterDataValidator()

        self.logger.info(f"{LogEmoji.INFO} Using Core Gateway at: {self.core_gateway_url}")
        self.logger.info(f"{LogEmoji.INFO} Using DB Gateway at: {self.db_gateway_url}")
        self.logger.info(f"{LogEmoji.SUCCESS} Enhanced NLP + RAG pipeline initialized")
        self.logger.info(f"{LogEmoji.SUCCESS} Multilingual mapper initialized (vi/en/zh ‚Üí English)")
        self.logger.info(f"{LogEmoji.SUCCESS} Master data validator initialized (PostgreSQL)")

    def setup_routes(self):
        """Setup API routes"""

        @self.app.get("/master-data/districts")
        async def get_districts():
            """Get list of all districts from master data"""
            try:
                districts = await self.master_data_validator.get_districts_list()
                return {"districts": districts, "count": len(districts)}
            except Exception as e:
                self.logger.error(f"{LogEmoji.ERROR} Failed to get districts: {e}")
                raise HTTPException(status_code=500, detail=str(e))

        @self.app.get("/master-data/property-types")
        async def get_property_types():
            """Get list of all property types from master data"""
            try:
                property_types = await self.master_data_validator.get_property_types_list()
                return {"property_types": property_types, "count": len(property_types)}
            except Exception as e:
                self.logger.error(f"{LogEmoji.ERROR} Failed to get property types: {e}")
                raise HTTPException(status_code=500, detail=str(e))

        @self.app.get("/master-data/amenities")
        async def get_amenities(category: Optional[str] = None):
            """Get list of all amenities from master data"""
            try:
                amenities = await self.master_data_validator.get_amenities_list(category=category)
                return {"amenities": amenities, "count": len(amenities)}
            except Exception as e:
                self.logger.error(f"{LogEmoji.ERROR} Failed to get amenities: {e}")
                raise HTTPException(status_code=500, detail=str(e))

        @self.app.post("/extract-query-enhanced", response_model=EnhancedExtractionResponse)
        async def extract_from_query_enhanced(request: QueryExtractionRequest):
            """
            **NEW ENHANCED ENDPOINT** - Extract entities using 3-layer pipeline:
            1. NLP Pre-processing (rule-based)
            2. RAG Context Retrieval (similar properties)
            3. Enhanced LLM Extraction (with NLP + RAG context)
            4. Post-Validation (against DB distribution)

            This is the RECOMMENDED endpoint for production use!
            """
            try:
                self.logger.info(f"{LogEmoji.TARGET} Enhanced extraction for: '{request.query}'")

                # LAYER 1: NLP Pre-processing
                self.logger.info(f"{LogEmoji.AI} Layer 1: NLP Pre-processing...")
                nlp_entities = self.nlp_processor.extract_entities(request.query)
                nlp_confidence = self.nlp_processor.get_extraction_confidence(nlp_entities)
                self.logger.info(f"{LogEmoji.SUCCESS} NLP extracted {len(nlp_entities)} entities (confidence: {nlp_confidence:.2f})")

                # LAYER 2: RAG Context Retrieval
                self.logger.info(f"{LogEmoji.AI} Layer 2: RAG Context Retrieval...")
                rag_context = await self.rag_enhancer.get_context(
                    query=request.query,
                    nlp_entities=nlp_entities,
                    limit=5
                )
                rag_count = rag_context.get("retrieved_count", 0)
                self.logger.info(f"{LogEmoji.SUCCESS} RAG retrieved {rag_count} similar properties")

                # LAYER 3: Enhanced LLM Extraction
                self.logger.info(f"{LogEmoji.AI} Layer 3: Enhanced LLM Extraction...")
                llm_entities = await self._enhanced_llm_extraction(
                    query=request.query,
                    nlp_entities=nlp_entities,
                    rag_context=rag_context,
                    intent=request.intent
                )
                self.logger.info(f"{LogEmoji.SUCCESS} LLM extracted {len(llm_entities)} entities")

                # LAYER 4: Post-Validation
                self.logger.info(f"{LogEmoji.AI} Layer 4: Post-Validation...")
                validation_result = self.validator.validate(
                    entities=llm_entities,
                    nlp_entities=nlp_entities,
                    rag_context=rag_context
                )

                validated_entities = validation_result["validated_entities"]
                confidence = validation_result["confidence"]
                warnings = validation_result["warnings"]
                validation_details = validation_result["validation_details"]

                # CRITICAL: Normalize entities to English master data standard using PostgreSQL
                # This converts multilingual input (vi/zh) ‚Üí English for database storage
                self.logger.info(f"{LogEmoji.AI} Normalizing entities using PostgreSQL master data...")
                master_data_result = await self.master_data_validator.normalize_and_validate(
                    validated_entities
                )
                normalized_entities = master_data_result["normalized_entities"]
                master_data_warnings = master_data_result["warnings"]
                master_data_confidence = master_data_result["confidence"]

                # Combine warnings from both validators
                all_warnings = warnings + master_data_warnings

                # Update confidence (weighted average)
                final_confidence = (confidence * 0.5) + (master_data_confidence * 0.5)

                self.logger.info(
                    f"{LogEmoji.SUCCESS} Entities normalized using master data: {normalized_entities}"
                )
                self.logger.info(
                    f"{LogEmoji.INFO} Master data confidence: {master_data_confidence:.2f}, "
                    f"Final confidence: {final_confidence:.2f}"
                )

                self.logger.info(
                    f"{LogEmoji.SUCCESS} Extraction complete! "
                    f"Final confidence: {final_confidence:.2f}, Total warnings: {len(all_warnings)}"
                )

                # NEW: Confidence-based clarification
                # If confidence too low, generate clarification questions
                needs_clarification = final_confidence < 0.7
                clarification_questions = []
                suggestions = []

                if needs_clarification:
                    self.logger.info(f"{LogEmoji.WARNING} Low confidence! Generating clarification questions...")
                    clarification_result = self._generate_clarification(
                        query=request.query,
                        entities=normalized_entities,
                        confidence=final_confidence,
                        rag_context=rag_context
                    )
                    clarification_questions = clarification_result["questions"]
                    suggestions = clarification_result["suggestions"]

                return EnhancedExtractionResponse(
                    entities=normalized_entities,  # Return master-data-normalized entities
                    confidence=final_confidence,
                    extracted_from="enhanced_pipeline_with_master_data",
                    nlp_entities=nlp_entities,
                    rag_retrieved_count=rag_count,
                    warnings=all_warnings,
                    validation_details=validation_details,
                    needs_clarification=needs_clarification,
                    clarification_questions=clarification_questions if needs_clarification else None,
                    suggestions=suggestions if needs_clarification else None
                )

            except Exception as e:
                self.logger.error(f"{LogEmoji.ERROR} Enhanced extraction failed: {e}")
                raise HTTPException(status_code=500, detail=str(e))

        @self.app.post("/extract-query", response_model=QueryExtractionResponse)
        async def extract_from_query(request: QueryExtractionRequest):
            """
            Extract entities from user search query
            This is what Orchestrator should call for SEARCH intent!
            """
            try:
                self.logger.info(f"{LogEmoji.TARGET} Extracting entities from query: '{request.query}'")

                # Build specialized prompt for query extraction (not full property description)
                prompt = self._build_query_extraction_prompt(request.query, request.intent)

                # Call LLM via Core Gateway
                entities = await self._call_llm_for_extraction(prompt)

                # Normalize to English master data
                self.logger.info(f"{LogEmoji.AI} Normalizing query entities to English...")
                normalized_entities = self.multilingual_mapper.normalize_entities(
                    entities,
                    source_lang="vi"
                )

                confidence = self._calculate_confidence(normalized_entities)

                self.logger.info(f"{LogEmoji.SUCCESS} Extracted entities (normalized): {normalized_entities}")

                return QueryExtractionResponse(
                    entities=normalized_entities,
                    confidence=confidence,
                    extracted_from="query"
                )

            except Exception as e:
                self.logger.error(f"{LogEmoji.ERROR} Entity extraction failed: {e}")
                raise HTTPException(status_code=500, detail=str(e))

        @self.app.post("/extract-property", response_model=QueryExtractionResponse)
        async def extract_from_property_description(request: QueryExtractionRequest):
            """
            Extract full property attributes from property description/listing
            Used for data enrichment, not for user queries
            """
            try:
                self.logger.info(f"{LogEmoji.TARGET} Extracting from property description (length: {len(request.query)})")

                # Use full extraction prompt for property descriptions
                prompt = AttributeExtractionPrompts.build_extraction_prompt(request.query, include_examples=True)

                entities = await self._call_llm_for_extraction(prompt)
                confidence = self._calculate_confidence(entities)

                return QueryExtractionResponse(
                    entities=entities,
                    confidence=confidence,
                    extracted_from="property_description"
                )

            except Exception as e:
                self.logger.error(f"{LogEmoji.ERROR} Property extraction failed: {e}")
                raise HTTPException(status_code=500, detail=str(e))

        @self.app.post("/extract-from-images", response_model=QueryExtractionResponse)
        async def extract_from_images(request: ImageExtractionRequest):
            """
            NEW ENDPOINT: Extract property attributes from images using GPT-4o Vision

            This enables users to upload property photos and automatically extract:
            - Property type (apartment, house, villa)
            - Room count (bedrooms, bathrooms)
            - Amenities (pool, gym, parking, garden)
            - Style (modern, classic, luxury)
            - Condition (new, renovated, needs work)

            Example use cases:
            - User uploads property photos ‚Üí auto-populate listing
            - User uploads photos while searching ‚Üí find similar properties
            - Agent uploads photos ‚Üí AI suggests price range
            """
            try:
                self.logger.info(
                    f"{LogEmoji.TARGET} Extracting from {len(request.images)} images "
                    f"(with context: {bool(request.text_context)})"
                )

                # Build vision prompt for property analysis
                vision_prompt = self._build_vision_extraction_prompt(request.text_context)

                # Call GPT-4o Vision via Core Gateway
                entities = await self._call_vision_for_extraction(
                    images=request.images,
                    prompt=vision_prompt
                )

                # Merge with text context if provided
                if request.text_context:
                    self.logger.info(f"{LogEmoji.AI} Merging vision extraction with text context...")
                    text_entities = await self._call_llm_for_extraction(
                        self._build_query_extraction_prompt(request.text_context)
                    )
                    # Merge entities (vision takes precedence for visual attributes)
                    entities = {**text_entities, **entities}

                confidence = self._calculate_confidence(entities)
                self.logger.info(f"{LogEmoji.SUCCESS} Extracted {len(entities)} entities from images")

                return QueryExtractionResponse(
                    entities=entities,
                    confidence=confidence,
                    extracted_from="images_vision"
                )

            except Exception as e:
                self.logger.error(f"{LogEmoji.ERROR} Image extraction failed: {e}")
                raise HTTPException(status_code=500, detail=str(e))

    def _build_query_extraction_prompt(self, query: str, intent: Optional[str] = None) -> str:
        """
        Build specialized prompt for extracting entities from USER QUERIES
        Simpler than full property extraction - focuses on search criteria
        """
        return f"""B·∫°n l√† chuy√™n gia tr√≠ch xu·∫•t th√¥ng tin t√¨m ki·∫øm b·∫•t ƒë·ªông s·∫£n t·ª´ c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng.

üéØ NHI·ªÜM V·ª§:
ƒê·ªçc c√¢u h·ªèi c·ªßa user v√† tr√≠ch xu·∫•t C√ÅC TI√äU CH√ç T√åM KI·∫æM th√†nh JSON.

üìä ENTITIES C·∫¶N TR√çCH XU·∫§T (ch·ªâ tr√≠ch xu·∫•t nh·ªØng g√¨ c√≥ trong c√¢u h·ªèi):

**1. PROPERTY TYPE**
- property_type: cƒÉn h·ªô | nh√† ph·ªë | bi·ªát th·ª± | ƒë·∫•t | chung c∆∞ | commercial

**2. LOCATION**
- district: Qu·∫≠n/Huy·ªán (chu·∫©n h√≥a)
  * "Q7", "Q.7", "qu·∫≠n 7" ‚Üí "Qu·∫≠n 7"
  * "Q2" ‚Üí "Qu·∫≠n 2"
  * "B√¨nh Th·∫°nh" ‚Üí "Qu·∫≠n B√¨nh Th·∫°nh"
  * "Th·ªß ƒê·ª©c" ‚Üí "Qu·∫≠n Th·ªß ƒê·ª©c"
- ward: Ph∆∞·ªùng (n·∫øu c√≥)
- project_name: T√™n d·ª± √°n (Vinhomes, Masteri, etc.)

**3. PHYSICAL ATTRIBUTES**
- bedrooms: S·ªë ph√≤ng ng·ªß
  * "2PN" ‚Üí 2
  * "3 ph√≤ng ng·ªß" ‚Üí 3
  * "2 ph√≤ng" ‚Üí 2
- bathrooms: S·ªë ph√≤ng t·∫Øm/WC
- area: Di·ªán t√≠ch (m¬≤)
- min_area: Di·ªán t√≠ch t·ªëi thi·ªÉu
- max_area: Di·ªán t√≠ch t·ªëi ƒëa

**4. PRICE**
- price: Gi√° c·ª• th·ªÉ (VND)
- min_price: Gi√° t·ªëi thi·ªÉu (VND)
- max_price: Gi√° t·ªëi ƒëa (VND)

CHU·∫®N H√ìA GI√Å:
  * "d∆∞·ªõi 3 t·ª∑" ‚Üí max_price: 3000000000
  * "t·ª´ 2 ƒë·∫øn 5 t·ª∑" ‚Üí min_price: 2000000000, max_price: 5000000000
  * "kho·∫£ng 3 t·ª∑" ‚Üí price: 3000000000
  * "25 tri·ªáu/th√°ng" ‚Üí price: 25000000

**5. FEATURES**
- furniture: full | c∆° b·∫£n | kh√¥ng
- direction: ƒê√¥ng | T√¢y | Nam | B·∫Øc | etc.

**6. AMENITIES**
- parking: true n·∫øu c√≥ y√™u c·∫ßu ch·ªó ƒë·∫≠u xe
- elevator: true n·∫øu c√≥ y√™u c·∫ßu thang m√°y
- swimming_pool: true n·∫øu c√≥ y√™u c·∫ßu h·ªì b∆°i
- gym: true n·∫øu c√≥ y√™u c·∫ßu gym

üîç EXTRACTION RULES:

1. **Ch·ªâ tr√≠ch xu·∫•t th√¥ng tin C√ì TRONG C√ÇU H·ªéI** - ƒë·ª´ng b·ªãa th√™m
2. **Chu·∫©n h√≥a ƒë·ªãa danh** v·ªÅ format chu·∫©n
3. **Chu·∫©n h√≥a gi√°** v·ªÅ s·ªë VND
4. **N·∫øu kh√¥ng c√≥ th√¥ng tin** ‚Üí kh√¥ng ƒë∆∞a v√†o JSON (not null, just omit)
5. **∆Øu ti√™n t·ª´ kh√≥a r√µ r√†ng** h∆°n t·ª´ kh√≥a m∆° h·ªì

üìù FEW-SHOT EXAMPLES:

Example 1:
Input: "T√¨m cƒÉn h·ªô 2 ph√≤ng ng·ªß qu·∫≠n 7 d∆∞·ªõi 3 t·ª∑"
Output: {{"property_type": "cƒÉn h·ªô", "bedrooms": 2, "district": "Qu·∫≠n 7", "max_price": 3000000000}}

Example 2:
Input: "C·∫ßn mua nh√† ph·ªë B√¨nh Th·∫°nh kho·∫£ng 100m2"
Output: {{"property_type": "nh√† ph·ªë", "district": "Qu·∫≠n B√¨nh Th·∫°nh", "area": 100}}

Example 3:
Input: "T√¨m chung c∆∞ Vinhomes c√≥ h·ªì b∆°i"
Output: {{"property_type": "chung c∆∞", "project_name": "Vinhomes", "swimming_pool": true}}

Example 4:
Input: "Bi·ªát th·ª± Q2 t·ª´ 10 ƒë·∫øn 20 t·ª∑, c√≥ garage"
Output: {{"property_type": "bi·ªát th·ª±", "district": "Qu·∫≠n 2", "min_price": 10000000000, "max_price": 20000000000, "parking": true}}

üì• USER QUERY:
{query}

Intent: {intent or "SEARCH"}

üì§ OUTPUT (ch·ªâ JSON, kh√¥ng gi·∫£i th√≠ch):
"""

    async def _call_llm_for_extraction(self, prompt: str) -> Dict[str, Any]:
        """Call LLM via Core Gateway to extract entities"""
        try:
            llm_request = {
                "model": "gpt-4o-mini",
                "messages": [
                    {"role": "system", "content": "You are a structured data extraction expert. Always return valid JSON."},
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": 500,
                "temperature": 0.2  # Low temperature for consistent extraction
            }

            response = await self.http_client.post(
                f"{self.core_gateway_url}/chat/completions",
                json=llm_request,
                timeout=30.0
            )

            if response.status_code == 200:
                data = response.json()
                content = data.get("content", "").strip()

                # Clean up markdown code blocks
                content = re.sub(r'^```(?:json)?\s*\n?', '', content)
                content = re.sub(r'\n?```\s*$', '', content)
                content = content.strip()

                # Parse JSON
                entities = json.loads(content)
                return entities
            else:
                self.logger.warning(f"{LogEmoji.WARNING} Core Gateway returned {response.status_code}")
                return {}

        except json.JSONDecodeError as e:
            self.logger.error(f"{LogEmoji.ERROR} Failed to parse JSON: {e}")
            self.logger.error(f"Raw content: {content}")
            return {}
        except Exception as e:
            self.logger.error(f"{LogEmoji.ERROR} LLM call failed: {e}")
            return {}

    def _calculate_confidence(self, entities: Dict[str, Any]) -> float:
        """Calculate confidence score based on extracted entities"""
        if not entities:
            return 0.0

        # Simple confidence based on number of entities extracted
        num_entities = len(entities)
        if num_entities >= 4:
            return 0.95
        elif num_entities >= 3:
            return 0.85
        elif num_entities >= 2:
            return 0.75
        else:
            return 0.65

    async def _enhanced_llm_extraction(
        self,
        query: str,
        nlp_entities: Dict[str, Any],
        rag_context: Dict[str, Any],
        intent: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Enhanced LLM extraction with NLP hints and RAG context.

        This builds a rich prompt that includes:
        1. NLP pre-extracted entities (as hints)
        2. Real property examples from RAG
        3. Value ranges and patterns from DB
        """
        # Build enhanced prompt
        prompt = self._build_enhanced_prompt(query, nlp_entities, rag_context, intent)

        # Call LLM
        entities = await self._call_llm_for_extraction(prompt)

        return entities

    def _build_enhanced_prompt(
        self,
        query: str,
        nlp_entities: Dict[str, Any],
        rag_context: Dict[str, Any],
        intent: Optional[str] = None
    ) -> str:
        """
        Build enhanced prompt with NLP hints and RAG context.
        """
        # Get RAG components
        examples = rag_context.get("examples", [])
        patterns = rag_context.get("patterns", {})
        value_ranges = rag_context.get("value_ranges", {})

        # Format examples
        examples_text = ""
        if examples:
            examples_text = "üìö REAL PROPERTY EXAMPLES FROM DATABASE (similar to this query):\n"
            for i, ex in enumerate(examples[:3], 1):
                examples_text += f"\nExample {i}:\n{json.dumps(ex, indent=2, ensure_ascii=False)}\n"

        # Format patterns
        patterns_text = ""
        if patterns:
            patterns_text = "üìä COMMON PATTERNS IN SIMILAR PROPERTIES:\n"
            if "common_districts" in patterns:
                districts = [d["value"] for d in patterns["common_districts"][:3]]
                patterns_text += f"- Common districts: {', '.join(districts)}\n"
            if "common_property_types" in patterns:
                types = [t["value"] for t in patterns["common_property_types"][:3]]
                patterns_text += f"- Common property types: {', '.join(types)}\n"

        # Format value ranges
        ranges_text = ""
        if value_ranges:
            ranges_text = "üìà VALUE RANGES FROM SIMILAR PROPERTIES:\n"
            if "price" in value_ranges:
                pr = value_ranges["price"]
                ranges_text += f"- Price range: {pr['min']:,.0f} - {pr['max']:,.0f} VND (avg: {pr['avg']:,.0f})\n"
            if "area" in value_ranges:
                ar = value_ranges["area"]
                ranges_text += f"- Area range: {ar['min']:.0f} - {ar['max']:.0f} m¬≤ (avg: {ar['avg']:.0f})\n"

        # Format NLP hints
        nlp_hints_text = ""
        if nlp_entities:
            nlp_hints_text = f"üí° NLP PRE-EXTRACTED HINTS:\n{json.dumps(nlp_entities, indent=2, ensure_ascii=False)}\n"

        prompt = f"""B·∫°n l√† chuy√™n gia tr√≠ch xu·∫•t th√¥ng tin b·∫•t ƒë·ªông s·∫£n.

üéØ NHI·ªÜM V·ª§: Tr√≠ch xu·∫•t entities t·ª´ query, S·ª¨ D·ª§NG HINTS t·ª´ NLP v√† EXAMPLES t·ª´ database.

{nlp_hints_text}

{examples_text}

{patterns_text}

{ranges_text}

üîç EXTRACTION RULES:
1. **USE NLP hints as starting point** - ∆Øu ti√™n th√¥ng tin t·ª´ NLP layer
2. **FOLLOW patterns from real examples** - Tham kh·∫£o format t·ª´ DB
3. **STAY within typical value ranges** - Ki·ªÉm tra v·ªõi ranges t·ª´ DB
4. **DON'T hallucinate** - Ch·ªâ tr√≠ch xu·∫•t th√¥ng tin c√≥ trong query
5. **Chu·∫©n h√≥a format** - S·ª≠ d·ª•ng format gi·ªëng examples

üìä ENTITIES C·∫¶N TR√çCH XU·∫§T (ch·ªâ tr√≠ch xu·∫•t nh·ªØng g√¨ c√≥ trong c√¢u h·ªèi):

**1. PROPERTY TYPE**
- property_type: cƒÉn h·ªô | nh√† ph·ªë | bi·ªát th·ª± | ƒë·∫•t | chung c∆∞ | vƒÉn ph√≤ng

**2. LOCATION**
- district: Qu·∫≠n/Huy·ªán (chu·∫©n h√≥a nh∆∞ examples)
- ward: Ph∆∞·ªùng (n·∫øu c√≥)
- project_name: T√™n d·ª± √°n

**3. PHYSICAL ATTRIBUTES**
- bedrooms: S·ªë ph√≤ng ng·ªß
- bathrooms: S·ªë ph√≤ng t·∫Øm
- area: Di·ªán t√≠ch (m¬≤)
- floors: S·ªë t·∫ßng

**4. PRICE**
- price: Gi√° c·ª• th·ªÉ (VND)
- min_price: Gi√° t·ªëi thi·ªÉu (VND)
- max_price: Gi√° t·ªëi ƒëa (VND)

**5. FEATURES & AMENITIES**
- furniture: full | c∆° b·∫£n | kh√¥ng
- direction: H∆∞·ªõng nh√†
- parking: true/false
- elevator: true/false
- swimming_pool: true/false
- gym: true/false

üì• USER QUERY:
{query}

Intent: {intent or "SEARCH"}

üì§ OUTPUT (ch·ªâ JSON, kh√¥ng gi·∫£i th√≠ch):
"""
        return prompt

    def _build_vision_extraction_prompt(self, text_context: Optional[str] = None) -> str:
        """
        Build prompt for GPT-4o Vision to extract property attributes from images.

        Args:
            text_context: Optional text context to enhance extraction

        Returns:
            Vision prompt
        """
        prompt = """B·∫°n l√† chuy√™n gia ph√¢n t√≠ch h√¨nh ·∫£nh b·∫•t ƒë·ªông s·∫£n.

üéØ NHI·ªÜM V·ª§: Ph√¢n t√≠ch ·∫£nh property v√† tr√≠ch xu·∫•t th√¥ng tin th√†nh JSON.

üìä ENTITIES C·∫¶N TR√çCH XU·∫§T (ch·ªâ tr√≠ch xu·∫•t nh·ªØng g√¨ TH·∫§Y ƒê∆Ø·ª¢C trong ·∫£nh):

**1. PROPERTY TYPE (quan tr·ªçng nh·∫•t)**
- property_type: cƒÉn h·ªô | nh√† ph·ªë | bi·ªát th·ª± | ƒë·∫•t | studio | penthouse
  * Nh√¨n v√†o: C·∫•u tr√∫c, quy m√¥, ki·∫øn tr√∫c
  * CƒÉn h·ªô: Trong chung c∆∞, c√≥ ban c√¥ng nh·ªè
  * Nh√† ph·ªë: Nhi·ªÅu t·∫ßng, m·∫∑t ti·ªÅn h·∫πp
  * Bi·ªát th·ª±: R·ªông r√£i, c√≥ s√¢n v∆∞·ªùn

**2. ROOMS & SPACES**
- bedrooms: S·ªë ph√≤ng ng·ªß (ƒë·∫øm t·ª´ ·∫£nh - gi∆∞·ªùng, t·ªß qu·∫ßn √°o)
- bathrooms: S·ªë ph√≤ng t·∫Øm (nh√¨n th·∫•y toilet, b·ªìn t·∫Øm)
- living_rooms: S·ªë ph√≤ng kh√°ch
- kitchens: C√≥ b·∫øp kh√¥ng
- balconies: C√≥ ban c√¥ng kh√¥ng

**3. AMENITIES (Ti·ªán √≠ch nh√¨n th·∫•y)**
- swimming_pool: true n·∫øu th·∫•y h·ªì b∆°i
- gym: true n·∫øu th·∫•y ph√≤ng gym
- parking: true n·∫øu th·∫•y ch·ªó ƒë·∫≠u xe/garage
- garden: true n·∫øu th·∫•y s√¢n v∆∞·ªùn
- elevator: true n·∫øu th·∫•y thang m√°y
- security: C√≥ h·ªá th·ªëng b·∫£o v·ªá kh√¥ng (camera, c·ªïng b·∫£o v·ªá)

**4. STYLE & CONDITION**
- style: modern | classic | luxury | minimalist | industrial
  * Modern: ƒê∆∞·ªùng n√©t s·∫°ch s·∫Ω, t·ªëi gi·∫£n, m√†u tr·∫Øng/ghi
  * Classic: G·ªó, h·ªça ti·∫øt c·ªï ƒëi·ªÉn
  * Luxury: Sang tr·ªçng, ƒë√®n ch√πm, ƒë√° marble
- condition: new | excellent | good | needs_renovation
  * New: M·ªõi tinh, s·∫°ch s·∫Ω
  * Excellent: T·ªët, ƒë∆∞·ª£c maintain t·ªët
  * Good: ·ªîn, c√≥ d·∫•u hi·ªáu s·ª≠ d·ª•ng nh·∫π
  * Needs renovation: C≈©, c·∫ßn s·ª≠a ch·ªØa
- furnished: full | basic | unfurnished
  * Full: ƒê·∫ßy ƒë·ªß n·ªôi th·∫•t (gi∆∞·ªùng, b√†n, gh·∫ø, TV, t·ªß l·∫°nh)
  * Basic: C√≥ m·ªôt s·ªë n·ªôi th·∫•t c∆° b·∫£n
  * Unfurnished: Tr·ªëng, kh√¥ng n·ªôi th·∫•t

**5. VISUAL FEATURES**
- view: sea | city | garden | mountain | river (n·∫øu th·∫•y qua c·ª≠a s·ªï)
- direction: H∆∞·ªõng ban c√¥ng/c·ª≠a s·ªï ch√≠nh
- natural_light: high | medium | low (l∆∞·ª£ng √°nh s√°ng t·ª± nhi√™n)
- floor_material: wood | tile | marble | carpet (v·∫≠t li·ªáu s√†n nh√†)

**6. ESTIMATE (∆Ø·ªõc l∆∞·ª£ng t·ª´ ·∫£nh)**
- estimated_area_m2: ∆Ø·ªõc l∆∞·ª£ng di·ªán t√≠ch (n·∫øu c√≥ th·ªÉ)
- estimated_floors: S·ªë t·∫ßng (n·∫øu th·∫•y)

üîç EXTRACTION RULES:

1. **CH·ªà tr√≠ch xu·∫•t th√¥ng tin TH·∫§Y R√ï TRONG ·∫¢NH** - ƒë·ª´ng ƒëo√°n
2. **∆Øu ti√™n ƒë·ªô ch√≠nh x√°c** h∆°n l√† extract nhi·ªÅu
3. **N·∫øu kh√¥ng ch·∫Øc ‚Üí kh√¥ng ƒë∆∞a v√†o JSON** (omit field, don't guess)
4. **ƒê·∫øm ph√≤ng c·∫©n th·∫≠n** - ƒë·ª´ng nh·∫ßm l·∫´n
5. **Ph√¢n t√≠ch t·∫•t c·∫£ c√°c ·∫£nh** n·∫øu c√≥ nhi·ªÅu ·∫£nh

üìù EXAMPLES:

Example 1 (Luxury apartment):
Input: ·∫¢nh cƒÉn h·ªô cao c·∫•p, ph√≤ng kh√°ch r·ªông, sofa tr·∫Øng, view th√†nh ph·ªë
Output: {
  "property_type": "cƒÉn h·ªô",
  "living_rooms": 1,
  "style": "luxury",
  "furnished": "full",
  "view": "city",
  "natural_light": "high",
  "floor_material": "marble",
  "condition": "excellent"
}

Example 2 (Villa with pool):
Input: ·∫¢nh bi·ªát th·ª± 2 t·∫ßng, h·ªì b∆°i ngo√†i tr·ªùi, s√¢n v∆∞·ªùn r·ªông
Output: {
  "property_type": "bi·ªát th·ª±",
  "swimming_pool": true,
  "garden": true,
  "estimated_floors": 2,
  "style": "modern",
  "natural_light": "high",
  "condition": "new"
}

Example 3 (Simple bedroom):
Input: ·∫¢nh ph√≤ng ng·ªß ƒë∆°n gi·∫£n, gi∆∞·ªùng ƒë∆°n, t·ªß qu·∫ßn √°o
Output: {
  "bedrooms": 1,
  "furnished": "basic",
  "style": "minimalist",
  "condition": "good",
  "floor_material": "wood"
}
"""

        if text_context:
            prompt += f"\n\nüìù TEXT CONTEXT (from user):\n{text_context}\n\nUse this context to enhance extraction, but PRIORITIZE what you SEE in images.\n"

        prompt += "\nüì§ OUTPUT (ch·ªâ JSON, kh√¥ng gi·∫£i th√≠ch):"

        return prompt

    async def _call_vision_for_extraction(
        self,
        images: List[str],
        prompt: str
    ) -> Dict[str, Any]:
        """
        Call GPT-4o Vision via Core Gateway to extract entities from images.

        Args:
            images: List of base64-encoded images
            prompt: Extraction prompt

        Returns:
            Extracted entities dict
        """
        try:
            from shared.models.core_gateway import FileAttachment

            # Build vision request
            files = [
                FileAttachment(
                    filename=f"property_{i}.jpg",
                    mime_type="image/jpeg",
                    base64_data=img
                )
                for i, img in enumerate(images)
            ]

            # Use Core Gateway's vision endpoint
            llm_request = {
                "model": "gpt-4o",  # GPT-4o for vision
                "messages": [
                    {
                        "role": "system",
                        "content": "You are a property image analysis expert. Always return valid JSON."
                    },
                    {
                        "role": "user",
                        "content": prompt,
                        "files": [f.dict() for f in files]
                    }
                ],
                "max_tokens": 1000,
                "temperature": 0.2
            }

            response = await self.http_client.post(
                f"{self.core_gateway_url}/chat/completions",
                json=llm_request,
                timeout=60.0
            )

            if response.status_code == 200:
                data = response.json()
                content = data.get("content", "").strip()

                # Clean up markdown code blocks
                import re
                content = re.sub(r'^```(?:json)?\s*\n?', '', content)
                content = re.sub(r'\n?```\s*$', '', content)
                content = content.strip()

                # Parse JSON
                import json
                entities = json.loads(content)
                return entities
            else:
                self.logger.warning(f"{LogEmoji.WARNING} Vision API returned {response.status_code}")
                return {}

        except json.JSONDecodeError as e:
            self.logger.error(f"{LogEmoji.ERROR} Failed to parse vision response: {e}")
            return {}
        except Exception as e:
            self.logger.error(f"{LogEmoji.ERROR} Vision call failed: {e}")
            return {}

    def _generate_clarification(
        self,
        query: str,
        entities: Dict[str, Any],
        confidence: float,
        rag_context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Generate clarification questions and suggestions when confidence is low.

        Args:
            query: User query
            entities: Extracted entities
            confidence: Confidence score
            rag_context: RAG context with similar properties

        Returns:
            Dict with clarification questions and suggestions
        """
        questions = []
        suggestions = []

        # Check what's missing or unclear
        has_property_type = "property_type" in entities
        has_location = "district" in entities or "ward" in entities
        has_price = "price" in entities or "min_price" in entities or "max_price" in entities
        has_bedrooms = "bedrooms" in entities

        # Generate questions based on missing info
        if not has_property_type:
            questions.append("B·∫°n mu·ªën t√¨m lo·∫°i b·∫•t ƒë·ªông s·∫£n n√†o? (cƒÉn h·ªô, nh√† ph·ªë, bi·ªát th·ª±)")
            # Get suggestions from RAG
            if rag_context.get("patterns", {}).get("common_property_types"):
                property_type_suggestions = [
                    {
                        "value": pt["value"],
                        "count": pt["count"],
                        "label": f"{pt['value']} ({pt['count']} cƒÉn)"
                    }
                    for pt in rag_context["patterns"]["common_property_types"][:3]
                ]
                suggestions.append({
                    "field": "property_type",
                    "question": "Lo·∫°i b·∫•t ƒë·ªông s·∫£n",
                    "options": property_type_suggestions
                })

        if not has_location:
            questions.append("B·∫°n mu·ªën t√¨m ·ªü khu v·ª±c n√†o? (Qu·∫≠n/Huy·ªán)")
            # Get suggestions from RAG
            if rag_context.get("patterns", {}).get("common_districts"):
                district_suggestions = [
                    {
                        "value": d["value"],
                        "count": d["count"],
                        "label": f"{d['value']} ({d['count']} cƒÉn)"
                    }
                    for d in rag_context["patterns"]["common_districts"][:5]
                ]
                suggestions.append({
                    "field": "district",
                    "question": "Khu v·ª±c",
                    "options": district_suggestions
                })

        if not has_price:
            questions.append("Ng√¢n s√°ch c·ªßa b·∫°n l√† bao nhi√™u?")
            # Get price range from RAG
            if rag_context.get("value_ranges", {}).get("price"):
                price_range = rag_context["value_ranges"]["price"]
                price_suggestions = [
                    {
                        "value": "low",
                        "min": price_range["min"],
                        "max": price_range["avg"] * 0.7,
                        "label": f"D∆∞·ªõi {price_range['avg'] * 0.7 / 1_000_000_000:.1f} t·ª∑"
                    },
                    {
                        "value": "medium",
                        "min": price_range["avg"] * 0.7,
                        "max": price_range["avg"] * 1.3,
                        "label": f"{price_range['avg'] * 0.7 / 1_000_000_000:.1f} - {price_range['avg'] * 1.3 / 1_000_000_000:.1f} t·ª∑"
                    },
                    {
                        "value": "high",
                        "min": price_range["avg"] * 1.3,
                        "max": price_range["max"],
                        "label": f"Tr√™n {price_range['avg'] * 1.3 / 1_000_000_000:.1f} t·ª∑"
                    }
                ]
                suggestions.append({
                    "field": "price",
                    "question": "Ng√¢n s√°ch",
                    "options": price_suggestions
                })

        if not has_bedrooms:
            questions.append("B·∫°n c·∫ßn bao nhi√™u ph√≤ng ng·ªß?")
            suggestions.append({
                "field": "bedrooms",
                "question": "S·ªë ph√≤ng ng·ªß",
                "options": [
                    {"value": 1, "label": "1 ph√≤ng ng·ªß (Studio)"},
                    {"value": 2, "label": "2 ph√≤ng ng·ªß"},
                    {"value": 3, "label": "3 ph√≤ng ng·ªß"},
                    {"value": 4, "label": "4+ ph√≤ng ng·ªß"}
                ]
            })

        # If entities were extracted but confidence still low, ask for confirmation
        if entities and confidence < 0.6:
            questions.append(
                f"T√¥i hi·ªÉu b·∫°n ƒëang t√¨m: {self._format_entities_for_display(entities)}. ƒê√∫ng kh√¥ng?"
            )

        return {
            "questions": questions,
            "suggestions": suggestions,
            "reason": f"Confidence th·∫•p ({confidence:.2f}), c·∫ßn l√†m r√µ th√™m th√¥ng tin"
        }

    def _format_entities_for_display(self, entities: Dict[str, Any]) -> str:
        """Format entities for user-friendly display."""
        parts = []
        if "property_type" in entities:
            parts.append(entities["property_type"])
        if "bedrooms" in entities:
            parts.append(f"{entities['bedrooms']} ph√≤ng ng·ªß")
        if "district" in entities:
            parts.append(f"t·∫°i {entities['district']}")
        if "max_price" in entities:
            parts.append(f"d∆∞·ªõi {entities['max_price'] / 1_000_000_000:.1f} t·ª∑")
        elif "price" in entities:
            parts.append(f"kho·∫£ng {entities['price'] / 1_000_000_000:.1f} t·ª∑")

        return " ".join(parts) if parts else "b·∫•t ƒë·ªông s·∫£n"

    async def on_shutdown(self):
        """Cleanup on shutdown"""
        await self.http_client.aclose()
        await self.rag_enhancer.close()
        await self.master_data_validator.close()
        await super().on_shutdown()


# Create service instance at module level for uvicorn
service = AttributeExtractionService()
app = service.app

if __name__ == "__main__":
    service.run()
