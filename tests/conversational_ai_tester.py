"""
ğŸ¤– CONVERSATIONAL AI TESTER
============================

Giáº£ láº­p phiÃªn chat tháº­t cá»§a ngÆ°á»i dÃ¹ng:
1. Define personas/scenarios vá»›i thÃ´ng sá»‘ trÆ°á»›c (budget, location, family size...)
2. AI generates contextual questions turn-by-turn
3. Maintains conversation history
4. Analyzes responses and continues naturally
5. Detects bugs during conversation flow
6. Creates bug reports for entire conversation

Example conversation:
Turn 1: "TÃ´i Ä‘ang tÃ¬m nhÃ  á»Ÿ Quáº­n 7 cho gia Ä‘Ã¬nh 4 ngÆ°á»i"
Turn 2: "Budget khoáº£ng 3-5 tá»·" (based on system asking)
Turn 3: "CÄƒn Ä‘áº§u tiÃªn cÃ³ view tá»‘t khÃ´ng?" (follow-up on results)
Turn 4: "So vá»›i cÄƒn thá»© 2 thÃ¬ sao?" (comparison based on context)
...
"""
import asyncio
import httpx
import json
import time
import os
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict, field
from enum import Enum


# Configuration
ORCHESTRATOR_URL = os.getenv("ORCHESTRATOR_URL", "http://localhost:8090")
OLLAMA_URL = os.getenv("OLLAMA_URL", "http://localhost:11434")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "llama3.2")
BUG_REPORTS_DIR = os.getenv("BUG_REPORTS_DIR", "/tmp/conversational_bug_reports")


class PersonaType(str, Enum):
    """CÃ¡c loáº¡i persona ngÆ°á»i dÃ¹ng"""
    FAMILY_WITH_KIDS = "family_with_kids"  # Gia Ä‘Ã¬nh cÃ³ con nhá»
    YOUNG_PROFESSIONAL = "young_professional"  # NgÆ°á»i tráº» Ä‘á»™c thÃ¢n
    INVESTOR = "investor"  # NhÃ  Ä‘áº§u tÆ°
    FIRST_TIME_BUYER = "first_time_buyer"  # NgÆ°á»i mua láº§n Ä‘áº§u
    ELDERLY_COUPLE = "elderly_couple"  # Cáº·p vá»£ chá»“ng lá»›n tuá»•i


@dataclass
class Persona:
    """ThÃ´ng tin persona ngÆ°á»i dÃ¹ng"""
    type: PersonaType
    name: str
    age_range: str
    family_size: int
    budget_range: str  # "3-5 tá»·"
    preferred_districts: List[str]
    requirements: List[str]  # ["gáº§n trÆ°á»ng há»c", "cÃ³ cÃ´ng viÃªn", "an ninh tá»‘t"]
    personality_traits: List[str]  # ["há»i nhiá»u", "quan tÃ¢m giÃ¡", "chi tiáº¿t"]
    conversation_turns: int = 7  # Number of turns in conversation


@dataclass
class ConversationTurn:
    """Má»™t turn trong conversation"""
    turn_number: int
    user_query: str
    system_response: Optional[str]
    intent_detected: Optional[str]
    confidence: float
    response_time_ms: float
    timestamp: str
    bugs_detected: List[Dict] = field(default_factory=list)
    ai_reasoning: Optional[str] = None  # AI's reasoning for next question


@dataclass
class ConversationSession:
    """ToÃ n bá»™ conversation session"""
    session_id: str
    persona: Persona
    turns: List[ConversationTurn] = field(default_factory=list)
    total_bugs: int = 0
    started_at: str = ""
    ended_at: str = ""
    successful_turns: int = 0


class ConversationalAI:
    """AI that generates contextual questions in a conversation"""

    def __init__(self, ollama_url: str = OLLAMA_URL, model: str = OLLAMA_MODEL):
        self.ollama_url = ollama_url
        self.model = model
        self.client = httpx.AsyncClient(timeout=90.0)

    async def generate_first_query(self, persona: Persona) -> Tuple[str, str]:
        """
        Generate first query based on persona
        Returns: (query, reasoning)
        """
        prompt = f"""Báº¡n lÃ  {persona.name}, {persona.age_range} tuá»•i, Ä‘ang tÃ¬m nhÃ  cho {persona.family_size} ngÆ°á»i.

THÃ”NG TIN:
- NgÃ¢n sÃ¡ch: {persona.budget_range}
- Khu vá»±c quan tÃ¢m: {', '.join(persona.preferred_districts)}
- YÃªu cáº§u: {', '.join(persona.requirements)}
- TÃ­nh cÃ¡ch: {', '.join(persona.personality_traits)}

NHIá»†M Vá»¤: Táº¡o cÃ¢u há»i Äáº¦U TIÃŠN Ä‘á»ƒ báº¯t Ä‘áº§u tÃ¬m nhÃ  vá»›i chatbot báº¥t Ä‘á»™ng sáº£n.

YÃŠU Cáº¦U:
- CÃ¢u há»i tá»± nhiÃªn, nhÆ° ngÆ°á»i Viá»‡t tháº­t nÃ³i chuyá»‡n
- KHÃ”NG Ä‘Æ°a háº¿t thÃ´ng tin vÃ o cÃ¢u Ä‘áº§u tiÃªn
- Báº¯t Ä‘áº§u khÃ¡i quÃ¡t, Ä‘á»ƒ chatbot há»i thÃªm chi tiáº¿t
- DÃ¹ng tiáº¿ng Viá»‡t

FORMAT:
QUERY: <cÃ¢u há»i>
REASONING: <lÃ½ do táº¡i sao há»i nhÆ° váº­y>
---

Táº¡o cÃ¢u há»i Ä‘áº§u tiÃªn:"""

        try:
            response = await self.client.post(
                f"{self.ollama_url}/api/generate",
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {"temperature": 0.7}
                }
            )

            if response.status_code == 200:
                data = response.json()
                text = data.get("response", "")
                return self._parse_query_response(text)

        except Exception as e:
            print(f"âŒ Failed to generate first query: {e}")

        # Fallback
        return (f"ChÃ o báº¡n! TÃ´i Ä‘ang tÃ¬m nhÃ  á»Ÿ {persona.preferred_districts[0]}.",
                "Starting conversation with location preference")

    async def generate_next_query(self,
                                  persona: Persona,
                                  conversation_history: List[ConversationTurn]) -> Tuple[str, str]:
        """
        Generate next query based on conversation history
        Returns: (query, reasoning)
        """
        # Build conversation context
        history_text = self._build_history_text(conversation_history)
        last_response = conversation_history[-1].system_response if conversation_history else ""

        prompt = f"""Báº¡n lÃ  {persona.name}, Ä‘ang chat vá»›i chatbot báº¥t Ä‘á»™ng sáº£n.

THÃ”NG TIN Cá»¦A Báº N:
- NgÃ¢n sÃ¡ch: {persona.budget_range}
- Khu vá»±c: {', '.join(persona.preferred_districts)}
- YÃªu cáº§u: {', '.join(persona.requirements)}
- TÃ­nh cÃ¡ch: {', '.join(persona.personality_traits)}
- Sá»‘ ngÆ°á»i: {persona.family_size}

Lá»ŠCH Sá»¬ TRÃ’ CHUYá»†N:
{history_text}

PHáº¢N Há»’I Má»šI NHáº¤T Tá»ª CHATBOT:
{last_response[:500]}

NHIá»†M Vá»¤: Táº¡o cÃ¢u há»i TIáº¾P THEO má»™t cÃ¡ch Tá»° NHIÃŠN.

QUY Táº®C:
1. Dá»±a vÃ o pháº£n há»“i chatbot vá»«a cho Ä‘á»ƒ há»i tiáº¿p
2. Náº¿u chatbot há»i thÃ´ng tin â†’ tráº£ lá»i cá»¥ thá»ƒ
3. Náº¿u chatbot cho káº¿t quáº£ â†’ há»i chi tiáº¿t vá» BÄS cá»¥ thá»ƒ
4. Náº¿u chatbot giáº£i thÃ­ch â†’ follow-up hoáº·c chuyá»ƒn sang váº¥n Ä‘á» khÃ¡c
5. CÃ¢u há»i ngáº¯n gá»n, tá»± nhiÃªn nhÆ° ngÆ°á»i Viá»‡t
6. Thá»ƒ hiá»‡n tÃ­nh cÃ¡ch persona (há»i nhiá»u/quan tÃ¢m giÃ¡/chi tiáº¿t)

FORMAT:
QUERY: <cÃ¢u há»i tiáº¿p theo>
REASONING: <táº¡i sao há»i nhÆ° váº­y>
---

Táº¡o cÃ¢u há»i tiáº¿p theo:"""

        try:
            response = await self.client.post(
                f"{self.ollama_url}/api/generate",
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {"temperature": 0.8}
                }
            )

            if response.status_code == 200:
                data = response.json()
                text = data.get("response", "")
                return self._parse_query_response(text)

        except Exception as e:
            print(f"âŒ Failed to generate next query: {e}")

        # Fallback
        return ("Cáº£m Æ¡n báº¡n!", "Ending conversation")

    def _parse_query_response(self, text: str) -> Tuple[str, str]:
        """Parse AI response to get query and reasoning"""
        query = ""
        reasoning = ""

        for line in text.split("\n"):
            if line.startswith("QUERY:"):
                query = line.replace("QUERY:", "").strip()
            elif line.startswith("REASONING:"):
                reasoning = line.replace("REASONING:", "").strip()

        if not query:
            # Fallback: use first non-empty line
            lines = [l.strip() for l in text.split("\n") if l.strip()]
            query = lines[0] if lines else "Xin chÃ o"

        return (query, reasoning or "Generated query")

    def _build_history_text(self, history: List[ConversationTurn]) -> str:
        """Build conversation history text"""
        lines = []
        for turn in history[-3:]:  # Last 3 turns for context
            lines.append(f"Turn {turn.turn_number}:")
            lines.append(f"  Báº¡n: {turn.user_query}")
            lines.append(f"  Bot: {turn.system_response[:200] if turn.system_response else 'KhÃ´ng cÃ³ pháº£n há»“i'}")
        return "\n".join(lines)

    async def analyze_response(self,
                               response: str,
                               expected_context: str) -> Tuple[bool, List[Dict], str]:
        """
        Analyze if response is valid
        Returns: (is_valid, bugs, analysis_text)
        """
        prompt = f"""PhÃ¢n tÃ­ch pháº£n há»“i cá»§a chatbot báº¥t Ä‘á»™ng sáº£n:

CONTEXT: {expected_context}

PHáº¢N Há»’I:
{response[:800]}

NHIá»†M Vá»¤: ÄÃ¡nh giÃ¡ pháº£n há»“i cÃ³ Há»¢P Lá»† khÃ´ng.

KIá»‚M TRA:
1. CÃ³ tráº£ lá»i Ä‘Ãºng cÃ¢u há»i khÃ´ng?
2. ThÃ´ng tin cÃ³ liÃªn quan khÃ´ng?
3. CÃ³ lá»—i hiá»ƒn thá»‹ (JSON, "None", error message)?
4. CÃ³ yÃªu cáº§u thÃªm thÃ´ng tin há»£p lÃ½ khÃ´ng?
5. Äá»™ dÃ i pháº£n há»“i cÃ³ phÃ¹ há»£p khÃ´ng?

FORMAT:
VALID: yes/no
BUGS: <mÃ´ táº£ lá»—i náº¿u cÃ³>
ANALYSIS: <phÃ¢n tÃ­ch chi tiáº¿t>
---

PhÃ¢n tÃ­ch:"""

        try:
            response_obj = await self.client.post(
                f"{self.ollama_url}/api/generate",
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {"temperature": 0.3}
                }
            )

            if response_obj.status_code == 200:
                data = response_obj.json()
                text = data.get("response", "")
                return self._parse_analysis(text, response)

        except Exception as e:
            print(f"âš ï¸ Analysis failed: {e}")

        return (True, [], "Analysis skipped")

    def _parse_analysis(self, text: str, original_response: str) -> Tuple[bool, List[Dict], str]:
        """Parse analysis result"""
        is_valid = True
        bugs = []
        analysis = ""

        for line in text.split("\n"):
            if line.startswith("VALID:"):
                valid_text = line.replace("VALID:", "").strip().lower()
                is_valid = "yes" in valid_text
            elif line.startswith("BUGS:"):
                bug_text = line.replace("BUGS:", "").strip()
                if bug_text and bug_text.lower() != "none":
                    bugs.append({
                        "type": "ai_detected",
                        "severity": "medium",
                        "message": bug_text,
                        "evidence": original_response[:200]
                    })
            elif line.startswith("ANALYSIS:"):
                analysis = line.replace("ANALYSIS:", "").strip()

        # Additional rule-based checks
        if original_response:
            if "error" in original_response.lower() or "lá»—i" in original_response.lower():
                bugs.append({
                    "type": "error_in_response",
                    "severity": "high",
                    "message": "Response chá»©a thÃ´ng bÃ¡o lá»—i",
                    "evidence": original_response[:200]
                })

            if "None" in original_response or "null" in original_response.lower():
                bugs.append({
                    "type": "null_value_displayed",
                    "severity": "medium",
                    "message": "Response hiá»ƒn thá»‹ giÃ¡ trá»‹ null/None",
                    "evidence": original_response[:200]
                })

        return (is_valid, bugs, analysis or text)

    async def close(self):
        """Close HTTP client"""
        await self.client.aclose()


class ConversationExecutor:
    """Execute conversation with real system"""

    def __init__(self, orchestrator_url: str = ORCHESTRATOR_URL):
        self.orchestrator_url = orchestrator_url
        self.client = httpx.AsyncClient(timeout=120.0)

    async def send_message(self,
                          user_id: str,
                          conversation_id: str,
                          query: str) -> Tuple[Optional[str], Optional[str], float, float]:
        """
        Send message to orchestrator
        Returns: (response, intent, confidence, response_time_ms)
        """
        start_time = time.time()

        try:
            response = await self.client.post(
                f"{self.orchestrator_url}/orchestrate",
                json={
                    "user_id": user_id,
                    "conversation_id": conversation_id,
                    "query": query
                }
            )

            elapsed_ms = (time.time() - start_time) * 1000

            if response.status_code == 200:
                data = response.json()
                return (
                    data.get("response"),
                    data.get("intent"),
                    data.get("confidence", 0.0),
                    elapsed_ms
                )
            else:
                return (
                    f"HTTP Error {response.status_code}",
                    None,
                    0.0,
                    elapsed_ms
                )

        except Exception as e:
            elapsed_ms = (time.time() - start_time) * 1000
            return (
                f"Exception: {str(e)}",
                None,
                0.0,
                elapsed_ms
            )

    async def close(self):
        """Close HTTP client"""
        await self.client.aclose()


class ConversationalTester:
    """Main conversational testing system"""

    def __init__(self):
        self.ai = ConversationalAI()
        self.executor = ConversationExecutor()

    def create_personas(self) -> List[Persona]:
        """Create test personas"""
        return [
            Persona(
                type=PersonaType.FAMILY_WITH_KIDS,
                name="Chá»‹ Lan",
                age_range="35-40",
                family_size=4,
                budget_range="3-5 tá»·",
                preferred_districts=["Quáº­n 7", "Quáº­n 2", "Thá»§ Äá»©c"],
                requirements=["gáº§n trÆ°á»ng há»c", "cÃ³ cÃ´ng viÃªn", "an ninh tá»‘t", "khu compound"],
                personality_traits=["quan tÃ¢m chi tiáº¿t", "há»i vá» tiá»‡n Ã­ch", "so sÃ¡nh nhiá»u"],
                conversation_turns=8
            ),
            Persona(
                type=PersonaType.YOUNG_PROFESSIONAL,
                name="Anh Minh",
                age_range="28-32",
                family_size=1,
                budget_range="2-3 tá»·",
                preferred_districts=["Quáº­n 1", "Quáº­n 3", "BÃ¬nh Tháº¡nh"],
                requirements=["gáº§n cÃ´ng ty", "cÃ³ gym", "hiá»‡n Ä‘áº¡i", "giao thÃ´ng thuáº­n tiá»‡n"],
                personality_traits=["quyáº¿t Ä‘oÃ¡n", "quan tÃ¢m ROI", "há»i nhanh"],
                conversation_turns=6
            ),
            Persona(
                type=PersonaType.INVESTOR,
                name="Anh HÃ¹ng",
                age_range="40-45",
                family_size=2,
                budget_range="5-10 tá»·",
                preferred_districts=["Quáº­n 2", "Quáº­n 7", "Thá»§ Äá»©c"],
                requirements=["tiá»m nÄƒng tÄƒng giÃ¡", "cho thuÃª tá»‘t", "phÃ¡p lÃ½ rÃµ rÃ ng"],
                personality_traits=["há»i vá» Ä‘áº§u tÆ°", "so sÃ¡nh giÃ¡", "phÃ¢n tÃ­ch ká»¹"],
                conversation_turns=9
            ),
            Persona(
                type=PersonaType.FIRST_TIME_BUYER,
                name="Chá»‹ Mai",
                age_range="30-33",
                family_size=2,
                budget_range="2-4 tá»·",
                preferred_districts=["Quáº­n 9", "Thá»§ Äá»©c", "BÃ¬nh DÆ°Æ¡ng"],
                requirements=["giÃ¡ há»£p lÃ½", "dá»… vay ngÃ¢n hÃ ng", "thá»§ tá»¥c Ä‘Æ¡n giáº£n"],
                personality_traits=["há»i nhiá»u", "lo ngáº¡i thá»§ tá»¥c", "cáº§n hÆ°á»›ng dáº«n"],
                conversation_turns=10
            ),
        ]

    async def run_conversation_session(self, persona: Persona) -> ConversationSession:
        """Run a complete conversation session"""
        session_id = f"{persona.type.value}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        session = ConversationSession(
            session_id=session_id,
            persona=persona,
            started_at=datetime.now().isoformat()
        )

        print(f"\n{'='*70}")
        print(f"ğŸ­ CONVERSATION SESSION: {persona.name} ({persona.type.value})")
        print(f"   Budget: {persona.budget_range} | Districts: {', '.join(persona.preferred_districts)}")
        print(f"   Planned turns: {persona.conversation_turns}")
        print(f"{'='*70}\n")

        conversation_history = []

        # Turn 1: First query
        print(f"ğŸ”„ Generating first query...")
        first_query, reasoning = await self.ai.generate_first_query(persona)
        print(f"ğŸ’­ AI Reasoning: {reasoning}")

        for turn_num in range(1, persona.conversation_turns + 1):
            print(f"\n--- Turn {turn_num}/{persona.conversation_turns} ---")

            # Get query (first turn or generated)
            if turn_num == 1:
                query = first_query
                ai_reasoning = reasoning
            else:
                print(f"ğŸ”„ Generating next query based on conversation...")
                query, ai_reasoning = await self.ai.generate_next_query(persona, conversation_history)
                print(f"ğŸ’­ AI Reasoning: {ai_reasoning}")

            print(f"ğŸ‘¤ User: {query}")

            # Send to system
            response, intent, confidence, response_time = await self.executor.send_message(
                user_id=session_id,
                conversation_id=session_id,
                query=query
            )

            print(f"ğŸ¤– Bot: {response[:150]}...")
            print(f"ğŸ“Š Intent: {intent} | Confidence: {confidence:.2f} | Time: {response_time:.0f}ms")

            # Analyze response
            is_valid, bugs, analysis = await self.ai.analyze_response(
                response or "No response",
                expected_context=f"{persona.name} asked: {query}"
            )

            if bugs:
                print(f"ğŸ› Found {len(bugs)} bug(s):")
                for bug in bugs:
                    print(f"   - {bug['message']}")
            else:
                print(f"âœ… Response valid")

            # Record turn
            turn = ConversationTurn(
                turn_number=turn_num,
                user_query=query,
                system_response=response,
                intent_detected=intent,
                confidence=confidence,
                response_time_ms=response_time,
                timestamp=datetime.now().isoformat(),
                bugs_detected=bugs,
                ai_reasoning=ai_reasoning
            )

            conversation_history.append(turn)
            session.turns.append(turn)

            if bugs:
                session.total_bugs += len(bugs)
            else:
                session.successful_turns += 1

            # Check if should stop (too many errors or end of conversation)
            if not response or "táº¡m biá»‡t" in query.lower() or "cáº£m Æ¡n" in query.lower():
                if turn_num < persona.conversation_turns:
                    print(f"âš ï¸ Ending conversation early at turn {turn_num}")
                break

            # Small delay between turns
            await asyncio.sleep(2)

        session.ended_at = datetime.now().isoformat()

        # Summary
        print(f"\n{'='*70}")
        print(f"ğŸ“Š SESSION SUMMARY")
        print(f"   Total turns: {len(session.turns)}")
        print(f"   Successful turns: {session.successful_turns}")
        print(f"   Bugs found: {session.total_bugs}")
        print(f"   Success rate: {session.successful_turns/len(session.turns)*100:.1f}%")
        print(f"{'='*70}\n")

        return session

    def save_session_report(self, session: ConversationSession) -> str:
        """Save conversation session report"""
        os.makedirs(BUG_REPORTS_DIR, exist_ok=True)
        filename = f"SESSION_{session.session_id}.md"
        filepath = os.path.join(BUG_REPORTS_DIR, filename)

        content = f"""# Conversation Session Report: {session.persona.name}

**Session ID:** {session.session_id}
**Persona Type:** {session.persona.type.value}
**Duration:** {session.started_at} â†’ {session.ended_at}

---

## Persona Profile

- **Name:** {session.persona.name}
- **Age:** {session.persona.age_range}
- **Family Size:** {session.persona.family_size} ngÆ°á»i
- **Budget:** {session.persona.budget_range}
- **Preferred Districts:** {', '.join(session.persona.preferred_districts)}
- **Requirements:**
{chr(10).join(f'  - {req}' for req in session.persona.requirements)}
- **Personality:**
{chr(10).join(f'  - {trait}' for trait in session.persona.personality_traits)}

---

## Conversation Flow

"""

        for turn in session.turns:
            content += f"""### Turn {turn.turn_number}

**User Query:**
```
{turn.user_query}
```

**AI Reasoning:**
{turn.ai_reasoning or 'N/A'}

**System Response:**
```
{turn.system_response[:500] if turn.system_response else 'No response'}
```

**Metrics:**
- Intent: {turn.intent_detected or 'N/A'}
- Confidence: {turn.confidence:.2f}
- Response Time: {turn.response_time_ms:.0f}ms

"""

            if turn.bugs_detected:
                content += "**ğŸ› Bugs Detected:**\n"
                for bug in turn.bugs_detected:
                    content += f"- **[{bug.get('severity', 'unknown').upper()}]** {bug['message']}\n"
                    content += f"  Evidence: `{bug.get('evidence', 'N/A')[:100]}`\n"
                content += "\n"
            else:
                content += "**âœ… No bugs detected**\n\n"

            content += "---\n\n"

        # Summary
        content += f"""## Summary Statistics

| Metric | Value |
|--------|-------|
| Total Turns | {len(session.turns)} |
| Successful Turns | {session.successful_turns} |
| Total Bugs Found | {session.total_bugs} |
| Success Rate | {session.successful_turns/len(session.turns)*100:.1f}% |
| Avg Response Time | {sum(t.response_time_ms for t in session.turns) / len(session.turns):.0f}ms |
| Avg Confidence | {sum(t.confidence for t in session.turns) / len(session.turns):.2f} |

## Bug Breakdown

"""

        # Count bugs by type
        bug_types = {}
        for turn in session.turns:
            for bug in turn.bugs_detected:
                bug_type = bug.get('type', 'unknown')
                bug_types[bug_type] = bug_types.get(bug_type, 0) + 1

        if bug_types:
            for bug_type, count in sorted(bug_types.items(), key=lambda x: x[1], reverse=True):
                content += f"- **{bug_type}**: {count} occurrence(s)\n"
        else:
            content += "No bugs found in this conversation.\n"

        content += f"""

---

**Generated by Conversational AI Tester**
**Full conversation JSON available for analysis**
"""

        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)

        # Also save JSON
        json_filepath = filepath.replace('.md', '.json')
        with open(json_filepath, 'w', encoding='utf-8') as f:
            json.dump(asdict(session), f, indent=2, ensure_ascii=False, default=str)

        return filepath

    async def run_all_personas(self):
        """Run tests for all personas"""
        personas = self.create_personas()

        print("ğŸ¤– CONVERSATIONAL AI TESTER")
        print("="*70)
        print(f"Testing {len(personas)} personas")
        print(f"Model: {OLLAMA_MODEL}")
        print(f"Orchestrator: {ORCHESTRATOR_URL}")
        print("="*70)

        all_sessions = []

        for i, persona in enumerate(personas, 1):
            print(f"\n\nğŸ­ Persona {i}/{len(personas)}")
            session = await self.run_conversation_session(persona)
            all_sessions.append(session)

            # Save report
            report_path = self.save_session_report(session)
            print(f"ğŸ“ Session report saved: {report_path}")

            # Delay between personas
            if i < len(personas):
                print(f"\nâ³ Waiting 5 seconds before next persona...")
                await asyncio.sleep(5)

        # Final summary
        print(f"\n\n{'='*70}")
        print("ğŸ“Š FINAL SUMMARY")
        print(f"{'='*70}")
        print(f"Total personas tested: {len(all_sessions)}")
        print(f"Total conversations: {len(all_sessions)}")
        print(f"Total turns: {sum(len(s.turns) for s in all_sessions)}")
        print(f"Total bugs found: {sum(s.total_bugs for s in all_sessions)}")
        print(f"Reports directory: {BUG_REPORTS_DIR}")
        print(f"{'='*70}\n")

    async def cleanup(self):
        """Cleanup resources"""
        await self.ai.close()
        await self.executor.close()


async def main():
    """Main entry point"""
    tester = ConversationalTester()

    try:
        await tester.run_all_personas()
    finally:
        await tester.cleanup()


if __name__ == "__main__":
    asyncio.run(main())
