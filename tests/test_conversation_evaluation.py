"""
Comprehensive Conversation Evaluation Test
Simulates 100 different user sessions with multi-turn conversations
Tests memory context, intent accuracy, and response quality
"""

import asyncio
import httpx
import json
import time
from datetime import datetime
from typing import List, Dict, Any
import random

# Test scenarios with realistic conversation flows
CONVERSATION_SCENARIOS = [
    # Scenario 1: Young couple looking for first home
    {
        "persona": "C·∫∑p v·ª£ ch·ªìng tr·∫ª, l·∫ßn ƒë·∫ßu mua nh√†",
        "budget": "2-3 t·ª∑",
        "conversation": [
            "Xin ch√†o, t√¥i mu·ªën t√¨m cƒÉn h·ªô cho gia ƒë√¨nh nh·ªè",
            "Ng√¢n s√°ch c·ªßa t√¥i kho·∫£ng 2-3 t·ª∑, qu·∫≠n n√†o ph√π h·ª£p?",
            "T√¨m cƒÉn 2 ph√≤ng ng·ªß qu·∫≠n 7 d∆∞·ªõi 3 t·ª∑ cho t√¥i",
            "CƒÉn n√†o c√≥ gi√° t·ªët nh·∫•t?",
            "Gi√° 2.5 t·ª∑ cho cƒÉn 70m¬≤ c√≥ h·ª£p l√Ω kh√¥ng?",
            "So s√°nh cƒÉn ƒë√≥ v·ªõi cƒÉn ·ªü Masteri Th·∫£o ƒêi·ªÅn",
            "Qu·∫≠n 7 c√≥ tr∆∞·ªùng h·ªçc n√†o g·∫ßn kh√¥ng?",
            "Th·ªß t·ª•c mua nh√† c·∫ßn gi·∫•y t·ªù g√¨?"
        ],
        "expected_intents": ["chat", "search", "search", "search", "price_analysis", "compare", "location_insights", "legal_guidance"],
        "context_tests": [
            {"turn": 3, "context_word": "qu·∫≠n", "previous_turn": 1},
            {"turn": 4, "context_word": "cƒÉn n√†o", "previous_turn": 2},
            {"turn": 5, "context_word": "cƒÉn", "previous_turn": 3},
            {"turn": 6, "context_word": "cƒÉn ƒë√≥", "previous_turn": 4}
        ]
    },

    # Scenario 2: Investor looking for ROI
    {
        "persona": "Nh√† ƒë·∫ßu t∆∞, t√¨m c∆° h·ªôi sinh l·ªùi",
        "budget": "5-10 t·ª∑",
        "conversation": [
            "T√¥i c√≥ 7 t·ª∑ mu·ªën ƒë·∫ßu t∆∞ b·∫•t ƒë·ªông s·∫£n",
            "N√™n ƒë·∫ßu t∆∞ v√†o qu·∫≠n 2 hay qu·∫≠n 7?",
            "T√¨m cƒÉn h·ªô cao c·∫•p qu·∫≠n 2 cho t√¥i",
            "So s√°nh Vinhomes Grand Park v·ªõi The Sun Avenue",
            "Khu v·ª±c n√†o c√≥ ti·ªÅm nƒÉng tƒÉng gi√° h∆°n?",
            "Masteri Th·∫£o ƒêi·ªÅn gi√° bao nhi√™u?",
            "C√≥ h·ª£p l√Ω kh√¥ng v·ªõi gi√° ƒë√≥?",
            "Th·ªß t·ª•c chuy·ªÉn nh∆∞·ª£ng nh∆∞ th·∫ø n√†o?"
        ],
        "expected_intents": ["chat", "investment_advice", "search", "compare", "investment_advice", "search", "price_analysis", "legal_guidance"]
    },

    # Scenario 3: Family upgrading home
    {
        "persona": "Gia ƒë√¨nh 4 ng∆∞·ªùi, n√¢ng c·∫•p nh√†",
        "budget": "4-6 t·ª∑",
        "conversation": [
            "Gia ƒë√¨nh t√¥i 4 ng∆∞·ªùi ƒëang ·ªü qu·∫≠n 10, mu·ªën chuy·ªÉn nh√† r·ªông h∆°n",
            "T√¨m cƒÉn 3 ph√≤ng ng·ªß qu·∫≠n 7 ho·∫∑c qu·∫≠n 2",
            "C√≥ cƒÉn n√†o g·∫ßn tr∆∞·ªùng qu·ªëc t·∫ø kh√¥ng?",
            "Qu·∫≠n Th·ªß ƒê·ª©c c√≥ ti·ªán √≠ch g√¨?",
            "So s√°nh gi√° qu·∫≠n 7 v·ªõi Th·ªß ƒê·ª©c",
            "CƒÉn 5 t·ª∑ 100m¬≤ c√≥ ƒë·∫Øt kh√¥ng?",
            "N√™n mua cƒÉn n√†o trong 2 cƒÉn v·ª´a t√¨m?"
        ],
        "expected_intents": ["chat", "search", "search", "location_insights", "compare", "price_analysis", "investment_advice"]
    },

    # Scenario 4: Retired couple downsizing
    {
        "persona": "V·ª£ ch·ªìng v·ªÅ h∆∞u, mu·ªën nh√† nh·ªè g·ªçn",
        "budget": "2-3 t·ª∑",
        "conversation": [
            "Ch√∫ng t√¥i v·ªÅ h∆∞u r·ªìi, mu·ªën b√°n nh√† l·ªõn mua cƒÉn nh·ªè h∆°n",
            "T√¨m cƒÉn 1-2 ph√≤ng ng·ªß y√™n tƒ©nh, g·∫ßn b·ªánh vi·ªán",
            "Qu·∫≠n n√†o ph√π h·ª£p v·ªõi ng∆∞·ªùi cao tu·ªïi?",
            "T√¨m cƒÉn h·ªô qu·∫≠n 3 ho·∫∑c qu·∫≠n 10 d∆∞·ªõi 3 t·ª∑",
            "C√≥ cƒÉn n√†o t·∫ßng th·∫•p kh√¥ng?",
            "Gi√° 2.8 t·ª∑ cho 65m¬≤ qu·∫≠n 3 c√≥ cao kh√¥ng?",
            "So s√°nh v·ªõi gi√° qu·∫≠n 10",
            "C·∫ßn gi·∫•y t·ªù g√¨ ƒë·ªÉ mua b√°n?"
        ],
        "expected_intents": ["chat", "search", "search", "search", "search", "price_analysis", "compare", "legal_guidance"]
    },

    # Scenario 5: Student looking for rental
    {
        "persona": "Sinh vi√™n, t√¨m cƒÉn h·ªô thu√™",
        "budget": "5-10 tri·ªáu/th√°ng",
        "conversation": [
            "Em l√† sinh vi√™n ƒêH B√°ch Khoa, c·∫ßn t√¨m ph√≤ng tr·ªç",
            "Khu v·ª±c Th·ªß ƒê·ª©c c√≥ ch·ªó n√†o gi√° sinh vi√™n kh√¥ng?",
            "T√¨m cƒÉn studio ho·∫∑c 1 ph√≤ng ng·ªß g·∫ßn tr∆∞·ªùng",
            "Khu ƒë√≥ c√≥ si√™u th·ªã, qu√°n ƒÉn g·∫ßn kh√¥ng?",
            "So s√°nh gi√° thu√™ qu·∫≠n Th·ªß ƒê·ª©c v·ªõi qu·∫≠n B√¨nh Th·∫°nh",
            "10 tri·ªáu/th√°ng cho 30m¬≤ c√≥ ƒë·∫Øt kh√¥ng?",
            "Thu√™ nh√† c·∫ßn gi·∫•y t·ªù g√¨?"
        ],
        "expected_intents": ["chat", "search", "search", "location_insights", "compare", "price_analysis", "legal_guidance"]
    }
]

# Generate more scenarios programmatically
def generate_additional_scenarios() -> List[Dict]:
    """Generate 95 more realistic scenarios"""

    templates = [
        # Template 1: Budget-focused searcher
        {
            "persona_template": "Ng∆∞·ªùi mua nh√† l·∫ßn ƒë·∫ßu, ng√¢n s√°ch {budget}",
            "conversation_template": [
                "T√¥i c√≥ {budget}, mu·ªën mua cƒÉn h·ªô {area}",
                "T√¨m cƒÉn {rooms} ph√≤ng ng·ªß {district} d∆∞·ªõi {max_price}",
                "CƒÉn n√†o c√≥ view ƒë·∫πp?",
                "Gi√° {price} cho {size}m¬≤ c√≥ h·ª£p l√Ω kh√¥ng?",
                "So s√°nh v·ªõi khu {compare_district}",
                "Khu ƒë√≥ c√≥ ti·ªán √≠ch g√¨?"
            ]
        },
        # Template 2: Location-focused
        {
            "persona_template": "Ng∆∞·ªùi t√¨m nh√† g·∫ßn n∆°i l√†m vi·ªác {workplace}",
            "conversation_template": [
                "T√¥i l√†m vi·ªác ·ªü {workplace}, mu·ªën t√¨m nh√† g·∫ßn",
                "Qu·∫≠n n√†o g·∫ßn {workplace} nh·∫•t?",
                "T√¨m cƒÉn h·ªô {district} trong ng√¢n s√°ch {budget}",
                "Khu ƒë√≥ c√≥ k·∫πt xe kh√¥ng?",
                "So s√°nh v·ªõi khu v·ª±c {alternative}",
                "Gi√° {price} c√≥ cao kh√¥ng?"
            ]
        },
        # Add more templates...
    ]

    districts = ["Qu·∫≠n 1", "Qu·∫≠n 2", "Qu·∫≠n 3", "Qu·∫≠n 7", "Qu·∫≠n 10", "Th·ªß ƒê·ª©c", "B√¨nh Th·∫°nh", "Ph√∫ Nhu·∫≠n"]
    budgets = ["2-3 t·ª∑", "3-5 t·ª∑", "5-7 t·ª∑", "tr√™n 10 t·ª∑"]
    rooms = ["1", "2", "3", "4"]

    additional_scenarios = []

    # Generate varied scenarios
    for i in range(95):
        budget = random.choice(budgets)
        district = random.choice(districts)
        room_count = random.choice(rooms)

        scenario = {
            "persona": f"Ng∆∞·ªùi d√πng {i+6} - {random.choice(['Gia ƒë√¨nh', 'C√° nh√¢n', 'Nh√† ƒë·∫ßu t∆∞'])}",
            "budget": budget,
            "conversation": [
                f"Xin ch√†o, t√¥i mu·ªën t√¨m nh√† t·∫°i {district}",
                f"Ng√¢n s√°ch {budget}, c√≥ cƒÉn n√†o ph√π h·ª£p?",
                f"T√¨m cƒÉn {room_count} ph√≤ng ng·ªß {district}",
                f"Khu {district} c√≥ ti·ªán √≠ch g√¨?",
                "So s√°nh v·ªõi khu v·ª±c l√¢n c·∫≠n",
                "Gi√° c√≥ h·ª£p l√Ω kh√¥ng?",
                "C·∫ßn chu·∫©n b·ªã gi·∫•y t·ªù g√¨?"
            ],
            "expected_intents": ["chat", "search", "search", "location_insights", "compare", "price_analysis", "legal_guidance"]
        }
        additional_scenarios.append(scenario)

    return additional_scenarios


class ConversationEvaluator:
    """Evaluates conversation quality with real API calls"""

    def __init__(self, orchestrator_url: str = "http://localhost:8090"):
        self.orchestrator_url = orchestrator_url
        self.client = httpx.AsyncClient(timeout=60.0)
        self.results = []

    async def run_conversation(self, scenario: Dict, session_id: str) -> Dict:
        """Run a full conversation scenario"""

        print(f"\n{'='*80}")
        print(f"üé≠ SCENARIO: {scenario['persona']}")
        print(f"üí∞ Budget: {scenario.get('budget', 'N/A')}")
        print(f"üìù Session ID: {session_id}")
        print(f"{'='*80}\n")

        conversation_results = {
            "session_id": session_id,
            "persona": scenario["persona"],
            "budget": scenario.get("budget"),
            "turns": [],
            "intent_accuracy": 0.0,
            "context_retention": 0.0,
            "avg_response_time": 0.0,
            "total_turns": len(scenario["conversation"]),
            "successful_turns": 0
        }

        conversation_history = []

        for turn_idx, user_message in enumerate(scenario["conversation"]):
            turn_num = turn_idx + 1
            print(f"\n{'‚îÄ'*80}")
            print(f"Turn {turn_num}/{len(scenario['conversation'])}")
            print(f"üë§ User: {user_message}")

            start_time = time.time()

            try:
                # Send message to orchestrator
                request_data = {
                    "user_id": session_id,
                    "query": user_message,
                    "conversation_id": session_id,
                    "metadata": {
                        "turn": turn_num,
                        "persona": scenario["persona"],
                        "history": conversation_history[-5:]  # Last 5 messages
                    }
                }

                response = await self.client.post(
                    f"{self.orchestrator_url}/orchestrate",
                    json=request_data
                )

                response_time = (time.time() - start_time) * 1000

                if response.status_code == 200:
                    data = response.json()

                    detected_intent = data.get("intent")
                    confidence = data.get("confidence", 0.0)
                    ai_response = data.get("response", "")
                    service_used = data.get("service_used", "unknown")

                    # Check if intent matches expected
                    expected_intent = scenario.get("expected_intents", [])[turn_idx] if turn_idx < len(scenario.get("expected_intents", [])) else None
                    intent_correct = detected_intent == expected_intent if expected_intent else None

                    print(f"ü§ñ Assistant: {ai_response[:200]}...")
                    print(f"\nüìä Metrics:")
                    print(f"   Intent: {detected_intent} (confidence: {confidence:.2f})")
                    if expected_intent:
                        print(f"   Expected: {expected_intent} {'‚úÖ' if intent_correct else '‚ùå'}")
                    print(f"   Service: {service_used}")
                    print(f"   Time: {response_time:.0f}ms")

                    # Store turn results
                    turn_result = {
                        "turn": turn_num,
                        "user_message": user_message,
                        "ai_response": ai_response,
                        "detected_intent": detected_intent,
                        "expected_intent": expected_intent,
                        "intent_correct": intent_correct,
                        "confidence": confidence,
                        "response_time_ms": response_time,
                        "service_used": service_used,
                        "success": True
                    }

                    conversation_results["turns"].append(turn_result)
                    conversation_results["successful_turns"] += 1

                    # Update conversation history
                    conversation_history.append({
                        "role": "user",
                        "content": user_message
                    })
                    conversation_history.append({
                        "role": "assistant",
                        "content": ai_response
                    })

                    # Brief pause between turns (simulate human typing)
                    await asyncio.sleep(1.5)

                else:
                    print(f"‚ùå Error: HTTP {response.status_code}")
                    conversation_results["turns"].append({
                        "turn": turn_num,
                        "user_message": user_message,
                        "error": f"HTTP {response.status_code}",
                        "success": False
                    })

            except Exception as e:
                print(f"‚ùå Exception: {str(e)}")
                conversation_results["turns"].append({
                    "turn": turn_num,
                    "user_message": user_message,
                    "error": str(e),
                    "success": False
                })

        # Calculate metrics
        successful_turns = [t for t in conversation_results["turns"] if t.get("success")]
        if successful_turns:
            # Intent accuracy
            intent_checks = [t for t in successful_turns if t.get("intent_correct") is not None]
            if intent_checks:
                correct_intents = sum(1 for t in intent_checks if t["intent_correct"])
                conversation_results["intent_accuracy"] = (correct_intents / len(intent_checks)) * 100

            # Average response time
            response_times = [t["response_time_ms"] for t in successful_turns]
            conversation_results["avg_response_time"] = sum(response_times) / len(response_times)

        # Context retention check
        context_tests = scenario.get("context_tests", [])
        if context_tests:
            context_passed = 0
            for test in context_tests:
                turn_idx = test["turn"] - 1
                if turn_idx < len(conversation_results["turns"]):
                    turn = conversation_results["turns"][turn_idx]
                    # Simple check: did the AI respond appropriately?
                    if turn.get("success") and turn.get("ai_response"):
                        context_passed += 1
            conversation_results["context_retention"] = (context_passed / len(context_tests)) * 100

        print(f"\n{'='*80}")
        print(f"üìà SESSION SUMMARY:")
        print(f"   Successful turns: {conversation_results['successful_turns']}/{conversation_results['total_turns']}")
        print(f"   Intent accuracy: {conversation_results['intent_accuracy']:.1f}%")
        print(f"   Context retention: {conversation_results['context_retention']:.1f}%")
        print(f"   Avg response time: {conversation_results['avg_response_time']:.0f}ms")
        print(f"{'='*80}\n")

        return conversation_results

    async def run_all_scenarios(self, scenarios: List[Dict], max_concurrent: int = 5):
        """Run all scenarios with concurrency control"""

        print(f"\nüöÄ Starting Conversation Evaluation")
        print(f"üìä Total scenarios: {len(scenarios)}")
        print(f"‚ö° Max concurrent: {max_concurrent}")
        print(f"‚è∞ Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

        # Run in batches to avoid overwhelming the system
        for i in range(0, len(scenarios), max_concurrent):
            batch = scenarios[i:i+max_concurrent]
            batch_num = (i // max_concurrent) + 1
            total_batches = (len(scenarios) + max_concurrent - 1) // max_concurrent

            print(f"\n{'#'*80}")
            print(f"# BATCH {batch_num}/{total_batches} ({len(batch)} scenarios)")
            print(f"{'#'*80}\n")

            tasks = []
            for idx, scenario in enumerate(batch):
                session_id = f"session_{i+idx+1:03d}_{int(time.time())}"
                tasks.append(self.run_conversation(scenario, session_id))

            batch_results = await asyncio.gather(*tasks, return_exceptions=True)

            for result in batch_results:
                if isinstance(result, Exception):
                    print(f"‚ùå Batch error: {result}")
                else:
                    self.results.append(result)

            # Pause between batches
            if i + max_concurrent < len(scenarios):
                print(f"\n‚è∏Ô∏è  Pausing 5 seconds before next batch...\n")
                await asyncio.sleep(5)

        await self.generate_report()

    async def generate_report(self):
        """Generate comprehensive evaluation report"""

        report_file = f"/tmp/conversation_evaluation_{int(time.time())}.json"
        summary_file = f"/tmp/conversation_summary_{int(time.time())}.md"

        # Calculate overall metrics
        total_turns = sum(r["total_turns"] for r in self.results)
        successful_turns = sum(r["successful_turns"] for r in self.results)
        avg_intent_accuracy = sum(r["intent_accuracy"] for r in self.results) / len(self.results) if self.results else 0
        avg_context_retention = sum(r["context_retention"] for r in self.results if r["context_retention"] > 0) / len([r for r in self.results if r["context_retention"] > 0]) if self.results else 0
        avg_response_time = sum(r["avg_response_time"] for r in self.results if r["avg_response_time"] > 0) / len([r for r in self.results if r["avg_response_time"] > 0]) if self.results else 0

        # Save detailed JSON
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump({
                "evaluation_date": datetime.now().isoformat(),
                "total_scenarios": len(self.results),
                "total_turns": total_turns,
                "successful_turns": successful_turns,
                "success_rate": (successful_turns / total_turns * 100) if total_turns > 0 else 0,
                "avg_intent_accuracy": avg_intent_accuracy,
                "avg_context_retention": avg_context_retention,
                "avg_response_time_ms": avg_response_time,
                "scenarios": self.results
            }, f, indent=2, ensure_ascii=False)

        # Generate markdown summary
        summary = f"""# Conversation Evaluation Report

**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## Overall Metrics

- **Total Scenarios**: {len(self.results)}
- **Total Conversation Turns**: {total_turns}
- **Successful Turns**: {successful_turns}/{total_turns} ({successful_turns/total_turns*100:.1f}%)
- **Average Intent Accuracy**: {avg_intent_accuracy:.1f}%
- **Average Context Retention**: {avg_context_retention:.1f}%
- **Average Response Time**: {avg_response_time:.0f}ms

## Top Performing Scenarios

"""

        # Sort by intent accuracy
        top_scenarios = sorted(self.results, key=lambda x: x.get("intent_accuracy", 0), reverse=True)[:10]

        summary += "| Rank | Persona | Intent Accuracy | Context Retention | Avg Response Time |\n"
        summary += "|------|---------|----------------|-------------------|------------------|\n"

        for idx, scenario in enumerate(top_scenarios, 1):
            summary += f"| {idx} | {scenario['persona'][:40]} | {scenario['intent_accuracy']:.1f}% | {scenario.get('context_retention', 0):.1f}% | {scenario.get('avg_response_time', 0):.0f}ms |\n"

        summary += "\n## Issues Found\n\n"

        # Find problematic scenarios
        issues = [r for r in self.results if r["successful_turns"] < r["total_turns"]]
        if issues:
            for issue in issues[:10]:
                failed_turns = [t for t in issue["turns"] if not t.get("success")]
                summary += f"- **{issue['persona']}**: {len(failed_turns)} failed turns\n"
                for turn in failed_turns:
                    summary += f"  - Turn {turn['turn']}: {turn.get('error', 'Unknown error')}\n"
        else:
            summary += "‚úÖ No issues found - all scenarios completed successfully!\n"

        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(summary)

        print(f"\n{'='*80}")
        print(f"üìä EVALUATION COMPLETE")
        print(f"{'='*80}")
        print(f"‚úÖ Scenarios completed: {len(self.results)}")
        print(f"üìà Success rate: {successful_turns/total_turns*100:.1f}%")
        print(f"üéØ Intent accuracy: {avg_intent_accuracy:.1f}%")
        print(f"üß† Context retention: {avg_context_retention:.1f}%")
        print(f"‚ö° Avg response time: {avg_response_time:.0f}ms")
        print(f"\nüìÑ Detailed report: {report_file}")
        print(f"üìù Summary: {summary_file}")
        print(f"{'='*80}\n")

    async def close(self):
        """Cleanup"""
        await self.client.aclose()


async def main():
    """Main evaluation function"""

    # Combine predefined and generated scenarios
    all_scenarios = CONVERSATION_SCENARIOS + generate_additional_scenarios()

    print(f"\n{'#'*80}")
    print(f"# REE AI CONVERSATION EVALUATION")
    print(f"# Total Scenarios: {len(all_scenarios)}")
    print(f"# Simulating real user conversations with memory context")
    print(f"{'#'*80}\n")

    evaluator = ConversationEvaluator()

    try:
        await evaluator.run_all_scenarios(all_scenarios, max_concurrent=3)
    finally:
        await evaluator.close()


if __name__ == "__main__":
    asyncio.run(main())
