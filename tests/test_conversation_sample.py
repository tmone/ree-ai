"""
Conversation Evaluation - Practical Sample
Runs 10 detailed scenarios to evaluate system intelligence
"""
import asyncio
import httpx
import json
import time
from datetime import datetime
from typing import List, Dict

# 10 representative scenarios covering different user types
EVALUATION_SCENARIOS = [
    {
        "persona": "Cáº·p vá»£ chá»“ng tráº», láº§n Ä‘áº§u mua nhÃ ",
        "budget": "2-3 tá»·",
        "characteristics": "Cáº§n tÆ° váº¥n toÃ n diá»‡n, cÃ³ nhiá»u cÃ¢u há»i cÆ¡ báº£n",
        "conversation": [
            ("Xin chÃ o, tÃ´i muá»‘n tÃ¬m cÄƒn há»™ cho gia Ä‘Ã¬nh nhá»", "chat"),
            ("NgÃ¢n sÃ¡ch cá»§a tÃ´i khoáº£ng 2-3 tá»·, quáº­n nÃ o phÃ¹ há»£p?", "search"),
            ("TÃ¬m cÄƒn 2 phÃ²ng ngá»§ quáº­n 7 dÆ°á»›i 3 tá»· cho tÃ´i", "search"),
            ("CÄƒn nÃ o cÃ³ giÃ¡ tá»‘t nháº¥t?", "search"),  # Test context
            ("GiÃ¡ 2.5 tá»· cho cÄƒn 70mÂ² cÃ³ há»£p lÃ½ khÃ´ng?", "price_analysis"),
            ("So sÃ¡nh cÄƒn Ä‘Ã³ vá»›i cÄƒn á»Ÿ Masteri Tháº£o Äiá»n", "compare"),  # Test "cÄƒn Ä‘Ã³" context
            ("Quáº­n 7 cÃ³ trÆ°á»ng há»c nÃ o gáº§n khÃ´ng?", "location_insights"),
            ("Thá»§ tá»¥c mua nhÃ  cáº§n giáº¥y tá» gÃ¬?", "legal_guidance")
        ],
        "context_tests": [
            {"turn": 4, "keyword": "CÄƒn nÃ o", "refers_to": "previous search results (turn 3)"},
            {"turn": 6, "keyword": "cÄƒn Ä‘Ã³", "refers_to": "previous property mentioned (turn 4-5)"}
        ]
    },
    {
        "persona": "NhÃ  Ä‘áº§u tÆ° cÃ³ kinh nghiá»‡m",
        "budget": "5-10 tá»·",
        "characteristics": "Quan tÃ¢m ROI, tiá»m nÄƒng sinh lá»i, phÃ¢n tÃ­ch ká»¹",
        "conversation": [
            ("NÃªn Ä‘áº§u tÆ° vÃ o quáº­n 2 hay quáº­n 7 vá»›i 5 tá»·?", "investment_advice"),
            ("Cho tÃ´i xem cÃ¡c dá»± Ã¡n quáº­n 2 trong nÄƒm tá»›i", "search"),
            ("So sÃ¡nh Vinhomes Grand Park vá»›i The Sun Avenue vá» tiá»m nÄƒng", "compare"),
            ("GiÃ¡ cÄƒn há»™ quáº­n 2 tÄƒng bao nhiÃªu % nÄƒm qua?", "price_analysis"),
            ("Khu vá»±c nÃ o cÃ³ háº¡ táº§ng phÃ¡t triá»ƒn máº¡nh?", "location_insights")
        ],
        "context_tests": [
            {"turn": 2, "keyword": "quáº­n 2", "refers_to": "investment area from turn 1"}
        ]
    },
    {
        "persona": "Gia Ä‘Ã¬nh cÃ³ con nhá»",
        "budget": "3-4 tá»·",
        "characteristics": "Æ¯u tiÃªn trÆ°á»ng há»c, cÃ´ng viÃªn, an toÃ n",
        "conversation": [
            ("TÃ¬m cÄƒn 3 phÃ²ng ngá»§ gáº§n trÆ°á»ng quá»‘c táº¿ quáº­n Thá»§ Äá»©c", "search"),
            ("Khu nÃ o cÃ³ nhiá»u trÆ°á»ng há»c tá»‘t?", "location_insights"),
            ("So sÃ¡nh Vinhomes Grand Park vá»›i Mizuki Park vá» tiá»‡n Ã­ch gia Ä‘Ã¬nh", "compare"),
            ("GiÃ¡ bao nhiÃªu lÃ  há»£p lÃ½ cho cÄƒn 90mÂ² gáº§n trÆ°á»ng?", "price_analysis")
        ],
        "context_tests": [
            {"turn": 3, "keyword": "Vinhomes Grand Park", "refers_to": "search area from turns 1-2"}
        ]
    },
    {
        "persona": "NgÆ°á»i vá» hÆ°u",
        "budget": "2-3 tá»·",
        "characteristics": "Æ¯u tiÃªn yÃªn tÄ©nh, gáº§n bá»‡nh viá»‡n, khÃ´ng vá»™i",
        "conversation": [
            ("TÃ´i muá»‘n tÃ¬m cÄƒn há»™ yÃªn tÄ©nh cho ngÆ°á»i cao tuá»•i", "search"),
            ("Quáº­n nÃ o cÃ³ nhiá»u bá»‡nh viá»‡n vÃ  gáº§n cÃ´ng viÃªn?", "location_insights"),
            ("Thá»§ tá»¥c mua nhÃ  cho ngÆ°á»i giÃ  cáº§n giáº¥y tá» gÃ¬ Ä‘áº·c biá»‡t?", "legal_guidance"),
            ("CÃ³ nÃªn mua cÄƒn chung cÆ° hay nhÃ  riÃªng?", "investment_advice")
        ],
        "context_tests": []
    },
    {
        "persona": "Sinh viÃªn thuÃª nhÃ ",
        "budget": "3-5 triá»‡u/thÃ¡ng",
        "characteristics": "NgÃ¢n sÃ¡ch tháº¥p, cáº§n gáº§n trÆ°á»ng, tiá»‡n Ã­ch",
        "conversation": [
            ("Cho thuÃª phÃ²ng gáº§n ÄH BÃ¡ch Khoa dÆ°á»›i 5 triá»‡u", "search"),
            ("Khu vá»±c Thá»§ Äá»©c cÃ³ quÃ¡n Äƒn vÃ  siÃªu thá»‹ khÃ´ng?", "location_insights"),
            ("So sÃ¡nh giÃ¡ thuÃª khu A vá»›i khu B", "compare"),
            ("5 triá»‡u thuÃª phÃ²ng 25mÂ² cÃ³ há»£p lÃ½ khÃ´ng?", "price_analysis")
        ],
        "context_tests": [
            {"turn": 3, "keyword": "khu A vá»›i khu B", "refers_to": "areas mentioned in previous turns"}
        ]
    },
    {
        "persona": "NgÆ°á»i nÆ°á»›c ngoÃ i mua nhÃ  táº¡i VN",
        "budget": "$150,000-200,000",
        "characteristics": "Cáº§n thÃ´ng tin phÃ¡p lÃ½, Æ°u tiÃªn khu expat",
        "conversation": [
            ("NgÆ°á»i nÆ°á»›c ngoÃ i cÃ³ thá»ƒ mua nhÃ  á»Ÿ Viá»‡t Nam khÃ´ng?", "legal_guidance"),
            ("TÃ¬m cÄƒn há»™ quáº­n 2 gáº§n trÆ°á»ng quá»‘c táº¿", "search"),
            ("Thá»§ tá»¥c mua nhÃ  cho ngÆ°á»i nÆ°á»›c ngoÃ i nhÆ° tháº¿ nÃ o?", "legal_guidance"),
            ("CÃ³ nÃªn mua á»Ÿ khu Tháº£o Äiá»n hay Vinhomes Central Park?", "investment_advice")
        ],
        "context_tests": []
    },
    {
        "persona": "NgÆ°á»i mua nhÃ  Ä‘á»ƒ cho thuÃª",
        "budget": "4-6 tá»·",
        "characteristics": "Quan tÃ¢m lá»£i suáº¥t cho thuÃª, vá»‹ trÃ­ Ä‘áº¯c Ä‘á»‹a",
        "conversation": [
            ("NÃªn mua cÄƒn nÃ o Ä‘á»ƒ cho thuÃª lá»£i nhuáº­n cao?", "investment_advice"),
            ("TÃ¬m cÄƒn 2PN gáº§n trung tÃ¢m quáº­n 1, 2, 7", "search"),
            ("So sÃ¡nh giÃ¡ cho thuÃª giá»¯a quáº­n 1 vÃ  quáº­n 7", "compare"),
            ("CÄƒn 80mÂ² giÃ¡ 5 tá»· cho thuÃª 20 triá»‡u/thÃ¡ng cÃ³ tá»‘t khÃ´ng?", "price_analysis")
        ],
        "context_tests": [
            {"turn": 4, "keyword": "CÄƒn 80mÂ²", "refers_to": "properties from search turns 2-3"}
        ]
    },
    {
        "persona": "NgÆ°á»i chá»‰ há»i thÄƒm, chÆ°a quyáº¿t Ä‘á»‹nh",
        "budget": "ChÆ°a xÃ¡c Ä‘á»‹nh",
        "characteristics": "CÃ¢u há»i chung chung, khÃ¡m phÃ¡ thá»‹ trÆ°á»ng",
        "conversation": [
            ("Thá»‹ trÆ°á»ng báº¥t Ä‘á»™ng sáº£n hiá»‡n nay ra sao?", "chat"),
            ("GiÃ¡ nhÃ  Ä‘ang tÄƒng hay giáº£m?", "price_analysis"),
            ("NÃªn Ä‘áº§u tÆ° bÃ¢y giá» hay Ä‘á»£i sau?", "investment_advice"),
            ("Báº¡n cÃ³ thá»ƒ tÆ° váº¥n cho tÃ´i khÃ´ng?", "chat")
        ],
        "context_tests": []
    },
    {
        "persona": "NgÆ°á»i bÃ¡n nhÃ ",
        "budget": "N/A",
        "characteristics": "Cáº§n Ä‘á»‹nh giÃ¡, marketing, tÆ° váº¥n bÃ¡n",
        "conversation": [
            ("TÃ´i muá»‘n bÃ¡n cÄƒn há»™ 2PN quáº­n 7", "chat"),
            ("GiÃ¡ bao nhiÃªu lÃ  há»£p lÃ½ Ä‘á»ƒ bÃ¡n nhanh?", "price_analysis"),
            ("Thá»§ tá»¥c bÃ¡n nhÃ  cáº§n chuáº©n bá»‹ nhá»¯ng gÃ¬?", "legal_guidance"),
            ("So sÃ¡nh giÃ¡ cÄƒn tÃ´i vá»›i thá»‹ trÆ°á»ng", "compare")
        ],
        "context_tests": [
            {"turn": 4, "keyword": "cÄƒn tÃ´i", "refers_to": "user's property from turn 1"}
        ]
    },
    {
        "persona": "NgÆ°á»i há»i vá» nhiá»u chá»§ Ä‘á» khÃ¡c nhau",
        "budget": "Varied",
        "characteristics": "Test kháº£ nÄƒng chuyá»ƒn Ä‘á»•i context",
        "conversation": [
            ("TÃ¬m cÄƒn há»™ quáº­n 2", "search"),
            ("Thá»§ tá»¥c mua nhÃ  nhÆ° tháº¿ nÃ o?", "legal_guidance"),
            ("Quay láº¡i váº¥n Ä‘á» tÃ¬m nhÃ , cÄƒn nÃ o giÃ¡ tá»‘t?", "search"),  # Context switch
            ("Báº¡n tÃªn lÃ  gÃ¬?", "chat"),
            ("Vá» cÄƒn há»™ vá»«a nÃ³i, cÃ³ gáº§n trÆ°á»ng há»c khÃ´ng?", "location_insights")  # Back to property
        ],
        "context_tests": [
            {"turn": 3, "keyword": "Quay láº¡i váº¥n Ä‘á» tÃ¬m nhÃ ", "refers_to": "search from turn 1"},
            {"turn": 5, "keyword": "cÄƒn há»™ vá»«a nÃ³i", "refers_to": "property from turn 3"}
        ]
    }
]

class ConversationEvaluator:
    def __init__(self, orchestrator_url: str = "http://localhost:8090"):
        self.orchestrator_url = orchestrator_url
        self.results = []

    async def run_conversation(self, scenario: Dict, session_num: int) -> Dict:
        """Run a single conversation scenario"""
        session_id = f"eval_session_{session_num:03d}"
        conversation = scenario["conversation"]

        print(f"\n{'='*80}")
        print(f"ðŸ“‹ Session {session_num}/10: {scenario['persona']}")
        print(f"ðŸ’° Budget: {scenario['budget']}")
        print(f"ðŸ“ Characteristics: {scenario['characteristics']}")
        print(f"{'='*80}\n")

        history = []
        turns_data = []

        async with httpx.AsyncClient(timeout=60.0) as client:
            for turn_num, (message, expected_intent) in enumerate(conversation, 1):
                print(f"\n{'â”€'*80}")
                print(f"Turn {turn_num}/{len(conversation)}")
                print(f"ðŸ‘¤ User: {message}")

                start_time = time.time()

                try:
                    request_data = {
                        "user_id": session_id,
                        "query": message,
                        "conversation_id": session_id,
                        "metadata": {
                            "turn": turn_num,
                            "history": history[-6:]  # Last 3 exchanges (6 messages)
                        }
                    }

                    response = await client.post(
                        f"{self.orchestrator_url}/orchestrate",
                        json=request_data
                    )

                    elapsed_ms = (time.time() - start_time) * 1000

                    if response.status_code == 200:
                        data = response.json()
                        intent = data.get("intent", "unknown")
                        confidence = data.get("confidence", 0)
                        ai_response = data.get("response", "")

                        # Intent match
                        intent_match = intent.lower() == expected_intent.lower()
                        status = "âœ…" if intent_match else "âŒ"

                        print(f"ðŸ¤– AI: {ai_response[:200]}{'...' if len(ai_response) > 200 else ''}")
                        print(f"\nðŸ“Š Intent: {intent} (expected: {expected_intent}) {status}")
                        print(f"   Confidence: {confidence:.2f}")
                        print(f"   Time: {elapsed_ms:.0f}ms")

                        # Store turn data
                        turn_data = {
                            "turn": turn_num,
                            "user_message": message,
                            "ai_response": ai_response,
                            "expected_intent": expected_intent,
                            "detected_intent": intent,
                            "confidence": confidence,
                            "intent_match": intent_match,
                            "response_time_ms": elapsed_ms
                        }
                        turns_data.append(turn_data)

                        # Update history
                        history.append({"role": "user", "content": message})
                        history.append({"role": "assistant", "content": ai_response})

                    else:
                        print(f"âŒ HTTP Error: {response.status_code}")
                        turns_data.append({
                            "turn": turn_num,
                            "user_message": message,
                            "error": f"HTTP {response.status_code}",
                            "expected_intent": expected_intent
                        })

                except Exception as e:
                    print(f"âŒ Exception: {str(e)}")
                    turns_data.append({
                        "turn": turn_num,
                        "user_message": message,
                        "error": str(e),
                        "expected_intent": expected_intent
                    })

                # Brief pause between turns
                await asyncio.sleep(0.5)

        # Calculate session metrics
        total_turns = len(turns_data)
        successful_turns = [t for t in turns_data if "error" not in t]
        intent_matches = [t for t in successful_turns if t.get("intent_match")]

        session_result = {
            "session_id": session_id,
            "persona": scenario["persona"],
            "budget": scenario["budget"],
            "characteristics": scenario["characteristics"],
            "total_turns": total_turns,
            "successful_turns": len(successful_turns),
            "intent_matches": len(intent_matches),
            "intent_accuracy": len(intent_matches) / total_turns if total_turns > 0 else 0,
            "avg_response_time_ms": sum(t.get("response_time_ms", 0) for t in successful_turns) / len(successful_turns) if successful_turns else 0,
            "turns": turns_data,
            "context_tests": scenario.get("context_tests", [])
        }

        print(f"\n{'â”€'*80}")
        print(f"ðŸ“Š Session Summary:")
        print(f"   Intent Accuracy: {session_result['intent_accuracy']*100:.1f}% ({len(intent_matches)}/{total_turns})")
        print(f"   Avg Response Time: {session_result['avg_response_time_ms']:.0f}ms")
        print(f"{'â”€'*80}\n")

        return session_result

    async def run_all_evaluations(self):
        """Run all 10 evaluation scenarios"""
        print("\n" + "="*80)
        print("ðŸ”¥ CONVERSATION EVALUATION - 10 Scenarios")
        print(f"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*80)

        for i, scenario in enumerate(EVALUATION_SCENARIOS, 1):
            result = await self.run_conversation(scenario, i)
            self.results.append(result)

        # Generate comprehensive report
        await self.generate_report()

    async def generate_report(self):
        """Generate detailed evaluation report"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # Calculate overall metrics
        total_turns = sum(r["total_turns"] for r in self.results)
        total_intent_matches = sum(r["intent_matches"] for r in self.results)
        overall_accuracy = total_intent_matches / total_turns if total_turns > 0 else 0
        avg_response_time = sum(r["avg_response_time_ms"] for r in self.results) / len(self.results) if self.results else 0

        # Save detailed JSON
        json_path = f"/tmp/conversation_evaluation_{timestamp}.json"
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump({
                "metadata": {
                    "timestamp": datetime.now().isoformat(),
                    "total_sessions": len(self.results),
                    "total_turns": total_turns,
                    "overall_intent_accuracy": overall_accuracy,
                    "avg_response_time_ms": avg_response_time
                },
                "sessions": self.results
            }, f, ensure_ascii=False, indent=2)

        # Generate markdown summary
        md_path = f"/tmp/conversation_evaluation_summary_{timestamp}.md"
        with open(md_path, "w", encoding="utf-8") as f:
            f.write("# Conversation Evaluation Report\n\n")
            f.write(f"**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"## Overall Metrics\n\n")
            f.write(f"- **Total Sessions**: {len(self.results)}\n")
            f.write(f"- **Total Turns**: {total_turns}\n")
            f.write(f"- **Overall Intent Accuracy**: {overall_accuracy*100:.1f}%\n")
            f.write(f"- **Average Response Time**: {avg_response_time:.0f}ms\n\n")

            f.write(f"## Session Results\n\n")
            for i, result in enumerate(self.results, 1):
                f.write(f"### Session {i}: {result['persona']}\n\n")
                f.write(f"- **Budget**: {result['budget']}\n")
                f.write(f"- **Intent Accuracy**: {result['intent_accuracy']*100:.1f}% ({result['intent_matches']}/{result['total_turns']})\n")
                f.write(f"- **Avg Response Time**: {result['avg_response_time_ms']:.0f}ms\n\n")

                # Conversation summary
                f.write("**Conversation Flow:**\n\n")
                for turn in result["turns"]:
                    match_icon = "âœ…" if turn.get("intent_match") else "âŒ"
                    if "error" in turn:
                        f.write(f"- Turn {turn['turn']}: âŒ ERROR - {turn['user_message'][:50]}...\n")
                    else:
                        f.write(f"- Turn {turn['turn']}: {match_icon} `{turn['detected_intent']}` (expected: `{turn['expected_intent']}`) - {turn['user_message'][:50]}...\n")
                f.write("\n")

                # Context tests
                if result.get("context_tests"):
                    f.write("**Context Tests:**\n\n")
                    for ctx_test in result["context_tests"]:
                        f.write(f"- Turn {ctx_test['turn']}: \"{ctx_test['keyword']}\" should refer to \"{ctx_test['refers_to']}\"\n")
                    f.write("\n")

                f.write("---\n\n")

            # Analysis section
            f.write("## Analysis\n\n")
            f.write("### Strengths\n\n")
            high_performers = [r for r in self.results if r["intent_accuracy"] >= 0.75]
            if high_performers:
                f.write(f"- {len(high_performers)}/10 sessions achieved â‰¥75% intent accuracy\n")
                f.write("- High-performing personas:\n")
                for hp in high_performers[:3]:
                    f.write(f"  - {hp['persona']}: {hp['intent_accuracy']*100:.1f}%\n")
            f.write("\n")

            f.write("### Weaknesses\n\n")
            low_performers = [r for r in self.results if r["intent_accuracy"] < 0.75]
            if low_performers:
                f.write(f"- {len(low_performers)}/10 sessions had <75% intent accuracy\n")
                f.write("- Challenging personas:\n")
                for lp in low_performers[:3]:
                    f.write(f"  - {lp['persona']}: {lp['intent_accuracy']*100:.1f}%\n")
            f.write("\n")

            f.write("### Recommendations\n\n")
            f.write("1. **Prompt Improvement**: Focus on failing intent types\n")
            f.write("2. **Context Handling**: Enhance conversation history management\n")
            f.write("3. **Response Quality**: Improve Vietnamese response generation\n")
            f.write("4. **Fine-tuning Data**: Use this evaluation data for model fine-tuning\n")

        print("\n" + "="*80)
        print("âœ… EVALUATION COMPLETE!")
        print("="*80)
        print(f"\nðŸ“Š Overall Intent Accuracy: {overall_accuracy*100:.1f}%")
        print(f"âš¡ Avg Response Time: {avg_response_time:.0f}ms")
        print(f"\nðŸ“ Detailed Report: {json_path}")
        print(f"ðŸ“„ Summary: {md_path}")
        print("="*80 + "\n")

async def main():
    evaluator = ConversationEvaluator()
    await evaluator.run_all_evaluations()

if __name__ == "__main__":
    asyncio.run(main())
